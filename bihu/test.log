[[1;36mINFO    [0m 04-05 11:45:09] [XZLog] [xzcfg.py:35:__init__] Configure file is /root/bihu24h/config.ini
['/usr/bin', '/usr/lib64/python27.zip', '/usr/lib64/python2.7', '/usr/lib64/python2.7/plat-linux2', '/usr/lib64/python2.7/lib-tk', '/usr/lib64/python2.7/lib-old', '/usr/lib64/python2.7/lib-dynload', '/usr/lib64/python2.7/site-packages', '/usr/lib64/python2.7/site-packages/gtk-2.0', '/usr/lib/python2.7/site-packages', '/root/bihu24h/bihu', '../', '../', '../']
[[1;36mINFO    [0m 04-05 11:45:09] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146174]
==================
set proxy[https://125.104.226.140:40991] artid[146174]
==================
==================
artid[146174] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 11:45:09] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146175]
==================
set proxy[https://125.104.226.140:40991] artid[146175]
==================
==================
artid[146175] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 11:45:09] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146176]
==================
set proxy[https://125.104.226.140:40991] artid[146176]
==================
==================
artid[146176] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 11:45:09] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146177]
==================
set proxy[https://125.104.226.140:40991] artid[146177]
==================
==================
artid[146177] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 11:45:09] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146178]
==================
set proxy[https://125.104.226.140:40991] artid[146178]
==================
==================
artid[146178] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 11:45:09] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146179]
==================
set proxy[https://125.104.226.140:40991] artid[146179]
==================
==================
artid[146179] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 11:45:09] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146180]
==================
set proxy[https://125.104.226.140:40991] artid[146180]
==================
==================
artid[146180] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 11:45:09] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146181]
==================
set proxy[https://125.104.226.140:40991] artid[146181]
==================
==================
artid[146181] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 11:45:09] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146182]
==================
set proxy[https://125.104.226.140:40991] artid[146182]
==================
==================
artid[146182] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 11:45:09] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146183]
==================
set proxy[https://125.104.226.140:40991] artid[146183]
==================
==================
artid[146183] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 11:45:09] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146184]
==================
set proxy[https://125.104.226.140:40991] artid[146184]
==================
==================
artid[146184] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 11:45:09] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146185]
==================
set proxy[https://125.104.226.140:40991] artid[146185]
==================
==================
artid[146185] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 11:45:09] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146186]
==================
set proxy[https://125.104.226.140:40991] artid[146186]
==================
==================
artid[146186] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 11:45:09] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146187]
==================
set proxy[https://125.104.226.140:40991] artid[146187]
==================
==================
artid[146187] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 11:45:09] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146188]
==================
set proxy[https://125.104.226.140:40991] artid[146188]
==================
==================
artid[146188] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 11:45:09] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146189]
==================
set proxy[https://125.104.226.140:40991] artid[146189]
==================
==================
artid[146189] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146174]
==================
==================
artid[146174] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146175]
==================
==================
artid[146175] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146176]
==================
==================
artid[146176] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146177]
==================
==================
artid[146177] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146178]
==================
==================
artid[146178] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146179]
==================
==================
artid[146179] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146180]
==================
==================
artid[146180] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146181]
==================
==================
artid[146181] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146182]
==================
==================
artid[146182] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146183]
==================
==================
artid[146183] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146184]
==================
==================
artid[146184] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146185]
==================
==================
artid[146185] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146186]
==================
==================
artid[146186] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146187]
==================
==================
artid[146187] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146188]
==================
==================
artid[146188] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146189]
==================
==================
artid[146189] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146174]
==================
==================
artid[146174] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146175]
==================
==================
artid[146175] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146176]
==================
==================
artid[146176] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146177]
==================
==================
artid[146177] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146178]
==================
==================
artid[146178] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146179]
==================
==================
artid[146179] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146180]
==================
==================
artid[146180] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146181]
==================
==================
artid[146181] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146182]
==================
==================
artid[146182] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146183]
==================
==================
artid[146183] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146184]
==================
==================
artid[146184] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146185]
==================
==================
artid[146185] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146186]
==================
==================
artid[146186] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146187]
==================
==================
artid[146187] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146188]
==================
==================
artid[146188] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146189]
==================
==================
artid[146189] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 11:46:24] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146190]
==================
set proxy[https://125.104.226.140:40991] artid[146190]
==================
==================
artid[146190] proxy_index[1]
==================
[[1;31mERROR   [0m 04-05 11:46:24] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 11:46:24] [XZLog] [article_week_loop.py:180:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:46:26] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
[[1;36mINFO    [0m 04-05 11:46:26] [XZLog] [HttpProxyMiddleware.py:187:invalid_proxy] invalidate {'count': 49, 'valid': True, 'proxy': 'https://125.104.226.140:40991'}
[[1;36mINFO    [0m 04-05 11:46:26] [XZLog] [HttpProxyMiddleware.py:143:inc_proxy_index] now using new proxy: https://202.120.37.202:1080
==================
set proxy[https://202.120.37.202:1080] artid[146174]
==================
==================
artid[146174] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:46:26] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 11:46:26] [XZLog] [article_week_loop.py:180:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:46:27] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146175]
==================
==================
artid[146175] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:46:27] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 11:46:27] [XZLog] [article_week_loop.py:180:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:46:29] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146176]
==================
==================
artid[146176] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:46:29] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 11:46:29] [XZLog] [article_week_loop.py:180:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:46:30] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146177]
==================
==================
artid[146177] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:46:30] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 11:46:30] [XZLog] [article_week_loop.py:180:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:46:32] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146178]
==================
==================
artid[146178] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:46:32] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 11:46:32] [XZLog] [article_week_loop.py:180:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:46:33] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146179]
==================
==================
artid[146179] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:46:33] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 11:46:33] [XZLog] [article_week_loop.py:180:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:46:34] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146180]
==================
==================
artid[146180] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:46:34] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 11:46:34] [XZLog] [article_week_loop.py:180:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:46:39] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146181]
==================
==================
artid[146181] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:46:39] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 11:46:39] [XZLog] [article_week_loop.py:180:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:46:41] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146182]
==================
==================
artid[146182] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:46:41] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 11:46:41] [XZLog] [article_week_loop.py:180:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:46:41] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146183]
==================
==================
artid[146183] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:46:41] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;36mINFO    [0m 04-05 11:46:42] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146191]
==================
set proxy[https://202.120.37.202:1080] artid[146191]
==================
==================
artid[146191] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 11:46:42] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146192]
==================
set proxy[https://202.120.37.202:1080] artid[146192]
==================
==================
artid[146192] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:46:42] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;31mERROR   [0m 04-05 11:46:42] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 11:46:42] [XZLog] [article_week_loop.py:180:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:46:43] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146184]
==================
==================
artid[146184] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:46:44] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;36mINFO    [0m 04-05 11:46:44] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146193]
==================
set proxy[https://202.120.37.202:1080] artid[146193]
==================
==================
artid[146193] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:46:44] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 11:46:44] [XZLog] [article_week_loop.py:180:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:46:45] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146185]
==================
==================
artid[146185] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:46:45] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;36mINFO    [0m 04-05 11:46:45] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146194]
==================
set proxy[https://202.120.37.202:1080] artid[146194]
==================
==================
artid[146194] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:46:45] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 11:46:45] [XZLog] [article_week_loop.py:180:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:46:46] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146186]
==================
==================
artid[146186] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:46:46] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;36mINFO    [0m 04-05 11:46:47] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146195]
==================
set proxy[https://202.120.37.202:1080] artid[146195]
==================
==================
artid[146195] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:46:47] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 11:46:47] [XZLog] [article_week_loop.py:180:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:46:47] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146187]
==================
==================
artid[146187] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:46:47] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;36mINFO    [0m 04-05 11:46:48] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146196]
==================
set proxy[https://202.120.37.202:1080] artid[146196]
==================
==================
artid[146196] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:46:48] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 11:46:48] [XZLog] [article_week_loop.py:180:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:46:48] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146188]
==================
==================
artid[146188] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:46:49] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;36mINFO    [0m 04-05 11:46:49] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146197]
==================
set proxy[https://202.120.37.202:1080] artid[146197]
==================
==================
artid[146197] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:46:49] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 11:46:49] [XZLog] [article_week_loop.py:180:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:46:50] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146189]
==================
==================
artid[146189] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:46:50] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;36mINFO    [0m 04-05 11:46:51] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146198]
==================
set proxy[https://202.120.37.202:1080] artid[146198]
==================
==================
artid[146198] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:46:51] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;36mINFO    [0m 04-05 11:46:53] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146199]
==================
set proxy[https://202.120.37.202:1080] artid[146199]
==================
==================
artid[146199] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:46:53] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://202.120.37.202:1080] artid[146191]
==================
==================
artid[146191] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146190]
==================
==================
artid[146190] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146192]
==================
==================
artid[146192] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 11:46:57] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146200]
==================
set proxy[https://202.120.37.202:1080] artid[146200]
==================
==================
artid[146200] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:46:57] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://202.120.37.202:1080] artid[146193]
==================
==================
artid[146193] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 11:46:59] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146201]
==================
set proxy[https://202.120.37.202:1080] artid[146201]
==================
==================
artid[146201] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:46:59] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://202.120.37.202:1080] artid[146194]
==================
==================
artid[146194] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 11:47:01] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146202]
==================
set proxy[https://202.120.37.202:1080] artid[146202]
==================
==================
artid[146202] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:47:01] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://202.120.37.202:1080] artid[146195]
==================
==================
artid[146195] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 11:47:04] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146203]
==================
set proxy[https://202.120.37.202:1080] artid[146203]
==================
==================
artid[146203] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:47:04] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://202.120.37.202:1080] artid[146196]
==================
==================
artid[146196] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 11:47:06] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146204]
==================
set proxy[https://202.120.37.202:1080] artid[146204]
==================
==================
artid[146204] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:47:06] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://202.120.37.202:1080] artid[146197]
==================
==================
artid[146197] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 11:47:08] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146205]
==================
set proxy[https://202.120.37.202:1080] artid[146205]
==================
==================
artid[146205] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:47:08] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://202.120.37.202:1080] artid[146198]
==================
==================
artid[146198] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146199]
==================
==================
artid[146199] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146191]
==================
==================
artid[146191] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146190]
==================
==================
artid[146190] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146192]
==================
==================
artid[146192] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146200]
==================
==================
artid[146200] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146193]
==================
==================
artid[146193] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146201]
==================
==================
artid[146201] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146194]
==================
==================
artid[146194] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146202]
==================
==================
artid[146202] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146195]
==================
==================
artid[146195] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146203]
==================
==================
artid[146203] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146196]
==================
==================
artid[146196] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146204]
==================
==================
artid[146204] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146197]
==================
==================
artid[146197] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146205]
==================
==================
artid[146205] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146198]
==================
==================
artid[146198] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146199]
==================
==================
artid[146199] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 11:47:32] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146206]
==================
set proxy[https://202.120.37.202:1080] artid[146206]
==================
==================
artid[146206] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:47:33] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;36mINFO    [0m 04-05 11:47:34] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146207]
==================
set proxy[https://202.120.37.202:1080] artid[146207]
==================
==================
artid[146207] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:47:34] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;36mINFO    [0m 04-05 11:47:35] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146208]
==================
set proxy[https://202.120.37.202:1080] artid[146208]
==================
==================
artid[146208] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:47:35] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://202.120.37.202:1080] artid[146200]
==================
==================
artid[146200] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 11:47:37] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146209]
==================
set proxy[https://202.120.37.202:1080] artid[146209]
==================
==================
artid[146209] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:47:37] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://202.120.37.202:1080] artid[146201]
==================
==================
artid[146201] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 11:47:39] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146210]
==================
set proxy[https://202.120.37.202:1080] artid[146210]
==================
==================
artid[146210] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:47:39] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://202.120.37.202:1080] artid[146202]
==================
==================
artid[146202] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 11:47:42] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146211]
==================
set proxy[https://202.120.37.202:1080] artid[146211]
==================
==================
artid[146211] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:47:42] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://202.120.37.202:1080] artid[146203]
==================
==================
artid[146203] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 11:47:44] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146212]
==================
set proxy[https://202.120.37.202:1080] artid[146212]
==================
==================
artid[146212] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:47:44] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://202.120.37.202:1080] artid[146204]
==================
==================
artid[146204] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 11:47:46] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146213]
==================
set proxy[https://202.120.37.202:1080] artid[146213]
==================
==================
artid[146213] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:47:46] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://202.120.37.202:1080] artid[146205]
==================
==================
artid[146205] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 11:47:49] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146214]
==================
set proxy[https://202.120.37.202:1080] artid[146214]
==================
==================
artid[146214] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:47:49] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;36mINFO    [0m 04-05 11:47:49] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146215]
==================
set proxy[https://202.120.37.202:1080] artid[146215]
==================
==================
artid[146215] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:47:49] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://202.120.37.202:1080] artid[146206]
==================
==================
artid[146206] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146207]
==================
==================
artid[146207] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146208]
==================
==================
artid[146208] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 11:47:55] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146216]
==================
set proxy[https://202.120.37.202:1080] artid[146216]
==================
==================
artid[146216] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:47:55] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://202.120.37.202:1080] artid[146209]
==================
==================
artid[146209] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 11:47:57] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146217]
==================
set proxy[https://202.120.37.202:1080] artid[146217]
==================
==================
artid[146217] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:47:57] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://202.120.37.202:1080] artid[146210]
==================
==================
artid[146210] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 11:48:00] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146218]
==================
set proxy[https://202.120.37.202:1080] artid[146218]
==================
==================
artid[146218] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:48:00] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://202.120.37.202:1080] artid[146211]
==================
==================
artid[146211] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 11:48:02] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146219]
==================
set proxy[https://202.120.37.202:1080] artid[146219]
==================
==================
artid[146219] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:48:02] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://202.120.37.202:1080] artid[146212]
==================
==================
artid[146212] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 11:48:04] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146220]
==================
set proxy[https://202.120.37.202:1080] artid[146220]
==================
==================
artid[146220] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:48:04] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://202.120.37.202:1080] artid[146213]
==================
==================
artid[146213] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 11:48:07] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146221]
==================
set proxy[https://202.120.37.202:1080] artid[146221]
==================
==================
artid[146221] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:48:07] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://202.120.37.202:1080] artid[146214]
==================
==================
artid[146214] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146215]
==================
==================
artid[146215] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146206]
==================
==================
artid[146206] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146208]
==================
==================
artid[146208] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146216]
==================
==================
artid[146216] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 11:48:16] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146222]
==================
set proxy[https://202.120.37.202:1080] artid[146222]
==================
==================
artid[146222] proxy_index[2]
==================
[[1;32mSUCC    [0m 04-05 11:48:16] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146207], title[为什么说虚拟货币是区块链存在的唯一意义]
[[1;32mSUCC    [0m 04-05 11:48:16] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146207], title[为什么说虚拟货币是区块链存在的唯一意义], table[article]
[[1;32mSUCC    [0m 04-05 11:48:16] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146207], title[为什么说虚拟货币是区块链存在的唯一意义]
[[1;36mINFO    [0m 04-05 11:48:18] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146223]
==================
set proxy[https://202.120.37.202:1080] artid[146223]
==================
==================
artid[146223] proxy_index[2]
==================
[[1;32mSUCC    [0m 04-05 11:48:18] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146209], title[3月28全网首发，智汇魔方2018横空出世，注册送矿机]
[[1;32mSUCC    [0m 04-05 11:48:18] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146209], title[3月28全网首发，智汇魔方2018横空出世，注册送矿机], table[article]
[[1;32mSUCC    [0m 04-05 11:48:18] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146209], title[3月28全网首发，智汇魔方2018横空出世，注册送矿机]
==================
set proxy[https://202.120.37.202:1080] artid[146210]
==================
==================
artid[146210] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146218]
==================
==================
artid[146218] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 11:48:21] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146224]
==================
set proxy[https://202.120.37.202:1080] artid[146224]
==================
==================
artid[146224] proxy_index[2]
==================
[[1;32mSUCC    [0m 04-05 11:48:21] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146217], title[【币圈晋级】如何在熊市中赚钱，反省牛市中亏钱！]
[[1;32mSUCC    [0m 04-05 11:48:21] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146217], title[【币圈晋级】如何在熊市中赚钱，反省牛市中亏钱！], table[article]
[[1;32mSUCC    [0m 04-05 11:48:22] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146217], title[【币圈晋级】如何在熊市中赚钱，反省牛市中亏钱！]
[[1;36mINFO    [0m 04-05 11:48:23] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146225]
==================
set proxy[https://202.120.37.202:1080] artid[146225]
==================
==================
artid[146225] proxy_index[2]
==================
[[1;32mSUCC    [0m 04-05 11:48:23] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146211], title[比特币大陆将在，五月坐庄以太坊eth]
[[1;32mSUCC    [0m 04-05 11:48:23] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146211], title[比特币大陆将在，五月坐庄以太坊eth], table[article]
[[1;32mSUCC    [0m 04-05 11:48:23] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146211], title[比特币大陆将在，五月坐庄以太坊eth]
[[1;36mINFO    [0m 04-05 11:48:24] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146226]
==================
set proxy[https://202.120.37.202:1080] artid[146226]
==================
==================
artid[146226] proxy_index[2]
==================
[[1;32mSUCC    [0m 04-05 11:48:24] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146219], title[]
[[1;32mSUCC    [0m 04-05 11:48:24] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146219], title[], table[article]
[[1;32mSUCC    [0m 04-05 11:48:24] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146219], title[]
[[1;36mINFO    [0m 04-05 11:48:26] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146227]
==================
set proxy[https://202.120.37.202:1080] artid[146227]
==================
==================
artid[146227] proxy_index[2]
==================
[[1;32mSUCC    [0m 04-05 11:48:26] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146212], title[李嘉诚退休了都那么看好区块链？]
[[1;32mSUCC    [0m 04-05 11:48:26] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146212], title[李嘉诚退休了都那么看好区块链？], table[article]
[[1;32mSUCC    [0m 04-05 11:48:26] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146212], title[李嘉诚退休了都那么看好区块链？]
[[1;36mINFO    [0m 04-05 11:48:27] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146228]
==================
set proxy[https://202.120.37.202:1080] artid[146228]
==================
==================
artid[146228] proxy_index[2]
==================
[[1;32mSUCC    [0m 04-05 11:48:27] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146220], title[也许eos反转之机并未成熟…]
[[1;32mSUCC    [0m 04-05 11:48:27] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146220], title[也许eos反转之机并未成熟…], table[article]
[[1;32mSUCC    [0m 04-05 11:48:27] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146220], title[也许eos反转之机并未成熟…]
[[1;36mINFO    [0m 04-05 11:48:28] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146229]
==================
set proxy[https://202.120.37.202:1080] artid[146229]
==================
==================
artid[146229] proxy_index[2]
==================
[[1;32mSUCC    [0m 04-05 11:48:28] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146213], title[8000元做投资，买完三年不动，选1-3种币，你会推荐什么？]
[[1;32mSUCC    [0m 04-05 11:48:28] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146213], title[8000元做投资，买完三年不动，选1-3种币，你会推荐什么？], table[article]
[[1;32mSUCC    [0m 04-05 11:48:28] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146213], title[8000元做投资，买完三年不动，选1-3种币，你会推荐什么？]
[[1;36mINFO    [0m 04-05 11:48:30] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146230]
==================
set proxy[https://202.120.37.202:1080] artid[146230]
==================
==================
artid[146230] proxy_index[2]
==================
[[1;32mSUCC    [0m 04-05 11:48:30] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146221], title[区块链世界的9大法则 你知道几条？]
[[1;32mSUCC    [0m 04-05 11:48:30] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146221], title[区块链世界的9大法则 你知道几条？], table[article]
[[1;32mSUCC    [0m 04-05 11:48:30] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146221], title[区块链世界的9大法则 你知道几条？]
==================
set proxy[https://202.120.37.202:1080] artid[146215]
==================
==================
artid[146215] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 11:48:31] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146231]
==================
set proxy[https://202.120.37.202:1080] artid[146231]
==================
==================
artid[146231] proxy_index[2]
==================
[[1;32mSUCC    [0m 04-05 11:48:31] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146214], title[【征文】 进化，担当，耐操——币圈人该有的样子；]
[[1;32mSUCC    [0m 04-05 11:48:31] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146214], title[【征文】 进化，担当，耐操——币圈人该有的样子；], table[article]
[[1;32mSUCC    [0m 04-05 11:48:31] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146214], title[【征文】 进化，担当，耐操——币圈人该有的样子；]
[[1;36mINFO    [0m 04-05 11:48:33] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146232]
==================
set proxy[https://202.120.37.202:1080] artid[146232]
==================
==================
artid[146232] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:48:33] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;36mINFO    [0m 04-05 11:48:33] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146233]
==================
set proxy[https://202.120.37.202:1080] artid[146233]
==================
==================
artid[146233] proxy_index[2]
==================
[[1;32mSUCC    [0m 04-05 11:48:33] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146206], title[我看到了财富的脚印]
[[1;32mSUCC    [0m 04-05 11:48:33] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146206], title[我看到了财富的脚印], table[article]
[[1;32mSUCC    [0m 04-05 11:48:33] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146206], title[我看到了财富的脚印]
[[1;36mINFO    [0m 04-05 11:48:35] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146234]
==================
set proxy[https://202.120.37.202:1080] artid[146234]
==================
==================
artid[146234] proxy_index[2]
==================
[[1;32mSUCC    [0m 04-05 11:48:35] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146216], title[必然没落的以太坊帝国]
[[1;32mSUCC    [0m 04-05 11:48:35] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146216], title[必然没落的以太坊帝国], table[article]
[[1;32mSUCC    [0m 04-05 11:48:35] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146216], title[必然没落的以太坊帝国]
[[1;36mINFO    [0m 04-05 11:48:36] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146235]
==================
set proxy[https://202.120.37.202:1080] artid[146235]
==================
==================
artid[146235] proxy_index[2]
==================
[[1;32mSUCC    [0m 04-05 11:48:36] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146222], title[交朋友的来]
[[1;32mSUCC    [0m 04-05 11:48:36] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146222], title[交朋友的来], table[article]
[[1;32mSUCC    [0m 04-05 11:48:36] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146222], title[交朋友的来]
[[1;36mINFO    [0m 04-05 11:48:38] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146236]
==================
set proxy[https://202.120.37.202:1080] artid[146236]
==================
==================
artid[146236] proxy_index[2]
==================
[[1;32mSUCC    [0m 04-05 11:48:38] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146223], title[传比特大陆以太坊矿机5月出货 吴忌寒欲率矿工集团控盘ETH]
[[1;32mSUCC    [0m 04-05 11:48:38] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146223], title[传比特大陆以太坊矿机5月出货 吴忌寒欲率矿工集团控盘ETH], table[article]
[[1;32mSUCC    [0m 04-05 11:48:38] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146223], title[传比特大陆以太坊矿机5月出货 吴忌寒欲率矿工集团控盘ETH]
[[1;36mINFO    [0m 04-05 11:48:39] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146237]
==================
set proxy[https://202.120.37.202:1080] artid[146237]
==================
==================
artid[146237] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146218]
==================
==================
artid[146218] proxy_index[2]
==================
[[1;32mSUCC    [0m 04-05 11:48:40] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146210], title[揭秘区块链项目生态体系]
[[1;32mSUCC    [0m 04-05 11:48:40] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146210], title[揭秘区块链项目生态体系], table[article]
[[1;32mSUCC    [0m 04-05 11:48:40] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146210], title[揭秘区块链项目生态体系]
[[1;36mINFO    [0m 04-05 11:48:41] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146238]
==================
set proxy[https://202.120.37.202:1080] artid[146238]
==================
==================
artid[146238] proxy_index[2]
==================
[[1;32mSUCC    [0m 04-05 11:48:41] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146224], title[]
[[1;32mSUCC    [0m 04-05 11:48:41] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146224], title[], table[article]
[[1;32mSUCC    [0m 04-05 11:48:41] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146224], title[]
[[1;36mINFO    [0m 04-05 11:48:42] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146239]
==================
set proxy[https://202.120.37.202:1080] artid[146239]
==================
==================
artid[146239] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:48:42] [XZLog] [article_week_loop.py:157:parse_item] unkown data structure! raw_str[{"data":null,"res":100004,"resMsg":""}]
[[1;32mSUCC    [0m 04-05 11:48:44] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146226], title[矿难了显卡就会降价？你可别做梦了]
[[1;32mSUCC    [0m 04-05 11:48:44] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146226], title[矿难了显卡就会降价？你可别做梦了], table[article]
[[1;32mSUCC    [0m 04-05 11:48:44] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146226], title[矿难了显卡就会降价？你可别做梦了]
[[1;32mSUCC    [0m 04-05 11:48:46] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146228], title[]
[[1;32mSUCC    [0m 04-05 11:48:46] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146228], title[], table[article]
[[1;32mSUCC    [0m 04-05 11:48:46] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146228], title[]
[[1;32mSUCC    [0m 04-05 11:48:47] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146229], title[比特币(BTC)的更新:低至7,638美元，可能会完成ABC的B波。]
[[1;32mSUCC    [0m 04-05 11:48:47] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146229], title[比特币(BTC)的更新:低至7,638美元，可能会完成ABC的B波。], table[article]
[[1;32mSUCC    [0m 04-05 11:48:47] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146229], title[比特币(BTC)的更新:低至7,638美元，可能会完成ABC的B波。]
[[1;32mSUCC    [0m 04-05 11:48:49] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146230], title[区块链不落地？你能将电子邮件系统整合到邮局？]
[[1;32mSUCC    [0m 04-05 11:48:49] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146230], title[区块链不落地？你能将电子邮件系统整合到邮局？], table[article]
[[1;32mSUCC    [0m 04-05 11:48:49] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146230], title[区块链不落地？你能将电子邮件系统整合到邮局？]
[[1;32mSUCC    [0m 04-05 11:48:50] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146215], title[3月28全网首发，智汇魔方2018横空出世，注册送矿机]
[[1;32mSUCC    [0m 04-05 11:48:50] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146215], title[3月28全网首发，智汇魔方2018横空出世，注册送矿机], table[article]
[[1;32mSUCC    [0m 04-05 11:48:50] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146215], title[3月28全网首发，智汇魔方2018横空出世，注册送矿机]
[[1;32mSUCC    [0m 04-05 11:48:51] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146231], title[换个视角，普通用户更应该保护锁KEY大户]
[[1;32mSUCC    [0m 04-05 11:48:51] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146231], title[换个视角，普通用户更应该保护锁KEY大户], table[article]
[[1;32mSUCC    [0m 04-05 11:48:51] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146231], title[换个视角，普通用户更应该保护锁KEY大户]
[[1;32mSUCC    [0m 04-05 11:48:52] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146232], title[谁说区块链上数据不可篡改？| 小白学比特币之五]
[[1;32mSUCC    [0m 04-05 11:48:53] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146232], title[谁说区块链上数据不可篡改？| 小白学比特币之五], table[article]
[[1;32mSUCC    [0m 04-05 11:49:28] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146232], title[谁说区块链上数据不可篡改？| 小白学比特币之五]
[[1;32mSUCC    [0m 04-05 11:49:29] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146233], title[2018区块链爆发]
[[1;32mSUCC    [0m 04-05 11:49:29] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146233], title[2018区块链爆发], table[article]
[[1;32mSUCC    [0m 04-05 11:49:29] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146233], title[2018区块链爆发]
[[1;32mSUCC    [0m 04-05 11:49:30] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146234], title[]
[[1;32mSUCC    [0m 04-05 11:49:30] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146234], title[], table[article]
[[1;32mSUCC    [0m 04-05 11:49:30] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146234], title[]
[[1;32mSUCC    [0m 04-05 11:49:31] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146235], title[「午间新闻」中国银行：对数字货币监管提出三点建议]
[[1;32mSUCC    [0m 04-05 11:49:31] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146235], title[「午间新闻」中国银行：对数字货币监管提出三点建议], table[article]
[[1;32mSUCC    [0m 04-05 11:49:32] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146235], title[「午间新闻」中国银行：对数字货币监管提出三点建议]
[[1;32mSUCC    [0m 04-05 11:49:33] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146236], title[EOS资料大全]
[[1;32mSUCC    [0m 04-05 11:49:33] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146236], title[EOS资料大全], table[article]
[[1;32mSUCC    [0m 04-05 11:49:33] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146236], title[EOS资料大全]
[[1;31mERROR   [0m 04-05 11:49:35] [XZLog] [article_week_loop.py:163:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;32mSUCC    [0m 04-05 11:49:35] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146237], title[如何使用互联网抢夺线下店铺生意？]
[[1;32mSUCC    [0m 04-05 11:49:35] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146237], title[如何使用互联网抢夺线下店铺生意？], table[article]
[[1;32mSUCC    [0m 04-05 11:49:35] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146237], title[如何使用互联网抢夺线下店铺生意？]
[[1;32mSUCC    [0m 04-05 11:49:37] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146238], title[万象笔记 | 002 | 最低工资法会保护弱者吗？]
[[1;32mSUCC    [0m 04-05 11:49:37] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146238], title[万象笔记 | 002 | 最低工资法会保护弱者吗？], table[article]
[[1;32mSUCC    [0m 04-05 11:49:37] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146238], title[万象笔记 | 002 | 最低工资法会保护弱者吗？]
[[1;32mSUCC    [0m 04-05 11:49:38] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146239], title[每天收一点。5分收KEY]
[[1;32mSUCC    [0m 04-05 11:49:38] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146239], title[每天收一点。5分收KEY], table[article]
[[1;32mSUCC    [0m 04-05 11:49:38] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146239], title[每天收一点。5分收KEY]
[[1;36mINFO    [0m 04-05 11:55:26] [XZLog] [xzcfg.py:35:__init__] Configure file is /root/bihu24h/config.ini
['/usr/bin', '/usr/lib64/python27.zip', '/usr/lib64/python2.7', '/usr/lib64/python2.7/plat-linux2', '/usr/lib64/python2.7/lib-tk', '/usr/lib64/python2.7/lib-old', '/usr/lib64/python2.7/lib-dynload', '/usr/lib64/python2.7/site-packages', '/usr/lib64/python2.7/site-packages/gtk-2.0', '/usr/lib/python2.7/site-packages', '/root/bihu24h/bihu', '../', '../', '../']
[[1;36mINFO    [0m 04-05 11:55:27] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146102]
==================
set proxy[https://125.104.226.140:40991] artid[146102]
==================
==================
artid[146102] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 11:55:27] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146103]
==================
set proxy[https://125.104.226.140:40991] artid[146103]
==================
==================
artid[146103] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 11:55:27] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146104]
==================
set proxy[https://125.104.226.140:40991] artid[146104]
==================
==================
artid[146104] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 11:55:27] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146105]
==================
set proxy[https://125.104.226.140:40991] artid[146105]
==================
==================
artid[146105] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 11:55:27] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146106]
==================
set proxy[https://125.104.226.140:40991] artid[146106]
==================
==================
artid[146106] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 11:55:27] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146107]
==================
set proxy[https://125.104.226.140:40991] artid[146107]
==================
==================
artid[146107] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 11:55:27] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146108]
==================
set proxy[https://125.104.226.140:40991] artid[146108]
==================
==================
artid[146108] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 11:55:27] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146109]
==================
set proxy[https://125.104.226.140:40991] artid[146109]
==================
==================
artid[146109] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 11:55:27] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146110]
==================
set proxy[https://125.104.226.140:40991] artid[146110]
==================
==================
artid[146110] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 11:55:27] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146111]
==================
set proxy[https://125.104.226.140:40991] artid[146111]
==================
==================
artid[146111] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 11:55:27] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146112]
==================
set proxy[https://125.104.226.140:40991] artid[146112]
==================
==================
artid[146112] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 11:55:27] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146113]
==================
set proxy[https://125.104.226.140:40991] artid[146113]
==================
==================
artid[146113] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 11:55:27] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146114]
==================
set proxy[https://125.104.226.140:40991] artid[146114]
==================
==================
artid[146114] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 11:55:27] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146115]
==================
set proxy[https://125.104.226.140:40991] artid[146115]
==================
==================
artid[146115] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 11:55:27] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146116]
==================
set proxy[https://125.104.226.140:40991] artid[146116]
==================
==================
artid[146116] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 11:55:27] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146117]
==================
set proxy[https://125.104.226.140:40991] artid[146117]
==================
==================
artid[146117] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146102]
==================
==================
artid[146102] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146103]
==================
==================
artid[146103] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146104]
==================
==================
artid[146104] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146105]
==================
==================
artid[146105] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146106]
==================
==================
artid[146106] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146107]
==================
==================
artid[146107] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146108]
==================
==================
artid[146108] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146109]
==================
==================
artid[146109] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146110]
==================
==================
artid[146110] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146111]
==================
==================
artid[146111] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146112]
==================
==================
artid[146112] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146113]
==================
==================
artid[146113] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146114]
==================
==================
artid[146114] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146115]
==================
==================
artid[146115] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146116]
==================
==================
artid[146116] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146117]
==================
==================
artid[146117] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146102]
==================
==================
artid[146102] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146103]
==================
==================
artid[146103] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146104]
==================
==================
artid[146104] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146105]
==================
==================
artid[146105] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146106]
==================
==================
artid[146106] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146107]
==================
==================
artid[146107] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146108]
==================
==================
artid[146108] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146109]
==================
==================
artid[146109] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146110]
==================
==================
artid[146110] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146111]
==================
==================
artid[146111] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146112]
==================
==================
artid[146112] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146113]
==================
==================
artid[146113] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146114]
==================
==================
artid[146114] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146115]
==================
==================
artid[146115] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146116]
==================
==================
artid[146116] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146117]
==================
==================
artid[146117] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 11:56:42] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146118]
==================
set proxy[https://125.104.226.140:40991] artid[146118]
==================
==================
artid[146118] proxy_index[1]
==================
[[1;31mERROR   [0m 04-05 11:56:42] [XZLog] [article_week_loop.py:166:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 11:56:42] [XZLog] [article_week_loop.py:183:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:56:43] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
[[1;36mINFO    [0m 04-05 11:56:43] [XZLog] [HttpProxyMiddleware.py:187:invalid_proxy] invalidate {'count': 49, 'valid': True, 'proxy': 'https://125.104.226.140:40991'}
[[1;36mINFO    [0m 04-05 11:56:43] [XZLog] [HttpProxyMiddleware.py:143:inc_proxy_index] now using new proxy: https://202.120.37.202:1080
==================
set proxy[https://202.120.37.202:1080] artid[146102]
==================
==================
artid[146102] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:56:43] [XZLog] [article_week_loop.py:166:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 11:56:43] [XZLog] [article_week_loop.py:183:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:56:45] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146103]
==================
==================
artid[146103] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:56:45] [XZLog] [article_week_loop.py:166:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 11:56:45] [XZLog] [article_week_loop.py:183:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:56:46] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146104]
==================
==================
artid[146104] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:56:46] [XZLog] [article_week_loop.py:166:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 11:56:46] [XZLog] [article_week_loop.py:183:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:56:47] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146105]
==================
==================
artid[146105] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:56:47] [XZLog] [article_week_loop.py:166:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 11:56:47] [XZLog] [article_week_loop.py:183:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:56:48] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146106]
==================
==================
artid[146106] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:56:48] [XZLog] [article_week_loop.py:166:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 11:56:48] [XZLog] [article_week_loop.py:183:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:56:49] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146107]
==================
==================
artid[146107] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:56:49] [XZLog] [article_week_loop.py:166:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 11:56:49] [XZLog] [article_week_loop.py:183:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:56:50] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146108]
==================
==================
artid[146108] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:56:50] [XZLog] [article_week_loop.py:166:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 11:56:50] [XZLog] [article_week_loop.py:183:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:56:57] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146109]
==================
==================
artid[146109] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:56:57] [XZLog] [article_week_loop.py:166:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 11:56:57] [XZLog] [article_week_loop.py:183:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:56:58] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146110]
==================
==================
artid[146110] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:56:58] [XZLog] [article_week_loop.py:166:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 11:56:58] [XZLog] [article_week_loop.py:183:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:56:58] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146111]
==================
==================
artid[146111] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:56:58] [XZLog] [article_week_loop.py:166:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;36mINFO    [0m 04-05 11:57:00] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146119]
==================
set proxy[https://202.120.37.202:1080] artid[146119]
==================
==================
artid[146119] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:57:00] [XZLog] [article_week_loop.py:166:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 11:57:00] [XZLog] [article_week_loop.py:183:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:57:01] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146112]
==================
==================
artid[146112] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:57:01] [XZLog] [article_week_loop.py:166:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 11:57:01] [XZLog] [article_week_loop.py:183:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:57:02] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146113]
==================
==================
artid[146113] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:57:02] [XZLog] [article_week_loop.py:166:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;36mINFO    [0m 04-05 11:57:02] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146120]
==================
set proxy[https://202.120.37.202:1080] artid[146120]
==================
==================
artid[146120] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:57:02] [XZLog] [article_week_loop.py:166:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 11:57:02] [XZLog] [article_week_loop.py:183:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:57:03] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146114]
==================
==================
artid[146114] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:57:03] [XZLog] [article_week_loop.py:166:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;36mINFO    [0m 04-05 11:57:04] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146121]
==================
set proxy[https://202.120.37.202:1080] artid[146121]
==================
==================
artid[146121] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:57:04] [XZLog] [article_week_loop.py:166:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 11:57:04] [XZLog] [article_week_loop.py:183:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:57:05] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146115]
==================
==================
artid[146115] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:57:05] [XZLog] [article_week_loop.py:166:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 11:57:05] [XZLog] [article_week_loop.py:183:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:57:05] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146116]
==================
==================
artid[146116] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:57:05] [XZLog] [article_week_loop.py:166:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;36mINFO    [0m 04-05 11:57:06] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146122]
==================
set proxy[https://202.120.37.202:1080] artid[146122]
==================
==================
artid[146122] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:57:06] [XZLog] [article_week_loop.py:166:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;36mINFO    [0m 04-05 11:57:06] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146123]
==================
set proxy[https://202.120.37.202:1080] artid[146123]
==================
==================
artid[146123] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:57:06] [XZLog] [article_week_loop.py:166:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 11:57:06] [XZLog] [article_week_loop.py:183:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:57:07] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146117]
==================
==================
artid[146117] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:57:08] [XZLog] [article_week_loop.py:166:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://202.120.37.202:1080] artid[146119]
==================
==================
artid[146119] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146118]
==================
==================
artid[146118] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 11:57:13] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146124]
==================
set proxy[https://202.120.37.202:1080] artid[146124]
==================
==================
artid[146124] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:57:13] [XZLog] [article_week_loop.py:166:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;36mINFO    [0m 04-05 11:57:14] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146125]
==================
set proxy[https://202.120.37.202:1080] artid[146125]
==================
==================
artid[146125] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 11:57:14] [XZLog] [article_week_loop.py:166:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://be02.bihu.com/bihube-pc/api/content/show/getArticle took longer than 15.0 seconds..>
[[1;33mWARNING [0m 04-05 11:57:14] [XZLog] [article_week_loop.py:183:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:57:14] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
[[1;36mINFO    [0m 04-05 11:57:14] [XZLog] [HttpProxyMiddleware.py:187:invalid_proxy] invalidate {'count': 25, 'valid': True, 'proxy': 'https://202.120.37.202:1080'}
[[1;36mINFO    [0m 04-05 11:57:14] [XZLog] [HttpProxyMiddleware.py:143:inc_proxy_index] now using new proxy: https://120.92.118.64:10010
==================
set proxy[https://120.92.118.64:10010] artid[146103]
==================
==================
artid[146103] proxy_index[3]
==================
==================
set proxy[https://120.92.118.64:10010] artid[146120]
==================
==================
artid[146120] proxy_index[3]
==================
[[1;31mERROR   [0m 04-05 11:57:15] [XZLog] [article_week_loop.py:166:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://be02.bihu.com/bihube-pc/api/content/show/getArticle took longer than 15.0 seconds..>
[[1;33mWARNING [0m 04-05 11:57:15] [XZLog] [article_week_loop.py:183:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:57:16] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://120.92.118.64:10010] artid[146104]
==================
==================
artid[146104] proxy_index[3]
==================
[[1;31mERROR   [0m 04-05 11:57:16] [XZLog] [article_week_loop.py:166:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://120.92.118.64:10010] artid[146121]
==================
==================
artid[146121] proxy_index[3]
==================
[[1;36mINFO    [0m 04-05 11:57:18] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146126]
==================
set proxy[https://120.92.118.64:10010] artid[146126]
==================
==================
artid[146126] proxy_index[3]
==================
[[1;31mERROR   [0m 04-05 11:57:18] [XZLog] [article_week_loop.py:166:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;36mINFO    [0m 04-05 11:57:19] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146127]
==================
set proxy[https://120.92.118.64:10010] artid[146127]
==================
==================
artid[146127] proxy_index[3]
==================
[[1;31mERROR   [0m 04-05 11:57:19] [XZLog] [article_week_loop.py:166:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://120.92.118.64:10010] artid[146123]
==================
==================
artid[146123] proxy_index[3]
==================
[[1;36mINFO    [0m 04-05 11:57:23] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146128]
==================
set proxy[https://120.92.118.64:10010] artid[146128]
==================
==================
artid[146128] proxy_index[3]
==================
[[1;31mERROR   [0m 04-05 11:57:23] [XZLog] [article_week_loop.py:166:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://be02.bihu.com/bihube-pc/api/content/show/getArticle took longer than 15.0 seconds..>
[[1;33mWARNING [0m 04-05 11:57:23] [XZLog] [article_week_loop.py:183:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:57:23] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://120.92.118.64:10010] artid[146110]
==================
==================
artid[146110] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 11:57:23] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146122], title[币圈高手必备的信息网络]
[[1;32mSUCC    [0m 04-05 11:57:24] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146122], title[币圈高手必备的信息网络], table[article]
[[1;32mSUCC    [0m 04-05 11:57:24] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146122], title[币圈高手必备的信息网络]
[[1;36mINFO    [0m 04-05 11:57:24] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146129]
==================
set proxy[https://120.92.118.64:10010] artid[146129]
==================
==================
artid[146129] proxy_index[3]
==================
[[1;31mERROR   [0m 04-05 11:57:24] [XZLog] [article_week_loop.py:166:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://be02.bihu.com/bihube-pc/api/content/show/getArticle took longer than 15.0 seconds..>
[[1;33mWARNING [0m 04-05 11:57:24] [XZLog] [article_week_loop.py:183:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:57:27] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://120.92.118.64:10010] artid[146111]
==================
==================
artid[146111] proxy_index[3]
==================
[[1;31mERROR   [0m 04-05 11:57:27] [XZLog] [article_week_loop.py:166:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://be02.bihu.com/bihube-pc/api/content/show/getArticle took longer than 15.0 seconds..>
[[1;33mWARNING [0m 04-05 11:57:27] [XZLog] [article_week_loop.py:183:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 11:57:28] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://120.92.118.64:10010] artid[146112]
==================
==================
artid[146112] proxy_index[3]
==================
[[1;36mINFO    [0m 04-05 11:57:29] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146130]
==================
set proxy[https://120.92.118.64:10010] artid[146130]
==================
==================
artid[146130] proxy_index[3]
==================
[[1;31mERROR   [0m 04-05 11:57:29] [XZLog] [article_week_loop.py:166:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;32mSUCC    [0m 04-05 11:57:29] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146119], title[列支敦士登将通过新立法促进区块链商业模式规范发展]
[[1;32mSUCC    [0m 04-05 11:57:29] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146119], title[列支敦士登将通过新立法促进区块链商业模式规范发展], table[article]
[[1;32mSUCC    [0m 04-05 11:57:29] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146119], title[列支敦士登将通过新立法促进区块链商业模式规范发展]
==================
set proxy[https://120.92.118.64:10010] artid[146118]
==================
==================
artid[146118] proxy_index[3]
==================
==================
set proxy[https://120.92.118.64:10010] artid[146124]
==================
==================
artid[146124] proxy_index[3]
==================
==================
set proxy[https://120.92.118.64:10010] artid[146125]
==================
==================
artid[146125] proxy_index[3]
==================
[[1;36mINFO    [0m 04-05 11:57:30] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146131]
==================
set proxy[https://120.92.118.64:10010] artid[146131]
==================
==================
artid[146131] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 11:57:30] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146103], title[凤凰网推出区块链产品“凤凰蛋’]
[[1;32mSUCC    [0m 04-05 11:57:30] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146103], title[凤凰网推出区块链产品“凤凰蛋’], table[article]
[[1;32mSUCC    [0m 04-05 11:57:30] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146103], title[凤凰网推出区块链产品“凤凰蛋’]
[[1;36mINFO    [0m 04-05 11:57:31] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146132]
==================
set proxy[https://120.92.118.64:10010] artid[146132]
==================
==================
artid[146132] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 11:57:31] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146120], title[ees超级能源！]
[[1;32mSUCC    [0m 04-05 11:57:31] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146120], title[ees超级能源！], table[article]
[[1;32mSUCC    [0m 04-05 11:57:31] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146120], title[ees超级能源！]
[[1;36mINFO    [0m 04-05 11:57:32] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146133]
==================
set proxy[https://120.92.118.64:10010] artid[146133]
==================
==================
artid[146133] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 11:57:32] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146104], title[万链之家-区块链时代的互助行业巨擘]
[[1;32mSUCC    [0m 04-05 11:57:32] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146104], title[万链之家-区块链时代的互助行业巨擘], table[article]
[[1;32mSUCC    [0m 04-05 11:57:32] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146104], title[万链之家-区块链时代的互助行业巨擘]
[[1;36mINFO    [0m 04-05 11:57:33] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146134]
==================
set proxy[https://120.92.118.64:10010] artid[146134]
==================
==================
artid[146134] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 11:57:33] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146121], title[浙江省省长袁家军:  加大新经济培育力度，力争在区块链、物联网等领域成为领跑者]
[[1;32mSUCC    [0m 04-05 11:57:33] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146121], title[浙江省省长袁家军:  加大新经济培育力度，力争在区块链、物联网等领域成为领跑者], table[article]
[[1;32mSUCC    [0m 04-05 11:57:34] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146121], title[浙江省省长袁家军:  加大新经济培育力度，力争在区块链、物联网等领域成为领跑者]
[[1;36mINFO    [0m 04-05 11:57:35] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146135]
==================
set proxy[https://120.92.118.64:10010] artid[146135]
==================
==================
artid[146135] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 11:57:35] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146126], title[央行发行的数字货币必然锚定人民币]
[[1;32mSUCC    [0m 04-05 11:57:35] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146126], title[央行发行的数字货币必然锚定人民币], table[article]
[[1;32mSUCC    [0m 04-05 11:57:35] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146126], title[央行发行的数字货币必然锚定人民币]
[[1;36mINFO    [0m 04-05 11:57:36] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146136]
==================
set proxy[https://120.92.118.64:10010] artid[146136]
==================
==================
artid[146136] proxy_index[3]
==================
[[1;31mERROR   [0m 04-05 11:57:36] [XZLog] [article_week_loop.py:160:parse_item] unkown data structure! artid[146127], raw_str[{"data":null,"res":100004,"resMsg":""}]
[[1;32mSUCC    [0m 04-05 11:57:38] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146123], title[3月29行情分析   昨晚闪蹦了么  没头绪看过来]
[[1;32mSUCC    [0m 04-05 11:57:38] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146123], title[3月29行情分析   昨晚闪蹦了么  没头绪看过来], table[article]
[[1;32mSUCC    [0m 04-05 11:57:38] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146123], title[3月29行情分析   昨晚闪蹦了么  没头绪看过来]
[[1;32mSUCC    [0m 04-05 11:57:39] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146128], title[微软中国区副总裁: 区块链并非数字货币]
[[1;32mSUCC    [0m 04-05 11:57:39] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146128], title[微软中国区副总裁: 区块链并非数字货币], table[article]
[[1;32mSUCC    [0m 04-05 11:57:39] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146128], title[微软中国区副总裁: 区块链并非数字货币]
[[1;32mSUCC    [0m 04-05 11:57:40] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146110], title[什么是区块链的共识机制？]
[[1;32mSUCC    [0m 04-05 11:57:40] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146110], title[什么是区块链的共识机制？], table[article]
[[1;32mSUCC    [0m 04-05 11:57:40] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146110], title[什么是区块链的共识机制？]
[[1;31mERROR   [0m 04-05 11:57:41] [XZLog] [article_week_loop.py:160:parse_item] unkown data structure! artid[146129], raw_str[{"data":null,"res":100004,"resMsg":""}]
[[1;32mSUCC    [0m 04-05 11:57:43] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146111], title[中国银行:  目前数字货币的主要发行方是私人部门]
[[1;32mSUCC    [0m 04-05 11:57:43] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146111], title[中国银行:  目前数字货币的主要发行方是私人部门], table[article]
[[1;32mSUCC    [0m 04-05 11:57:43] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146111], title[中国银行:  目前数字货币的主要发行方是私人部门]
[[1;32mSUCC    [0m 04-05 11:57:44] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146112], title[中VS美]
[[1;32mSUCC    [0m 04-05 11:57:44] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146112], title[中VS美], table[article]
[[1;32mSUCC    [0m 04-05 11:57:44] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146112], title[中VS美]
[[1;32mSUCC    [0m 04-05 11:57:45] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146130], title[Hi 币乎！]
[[1;32mSUCC    [0m 04-05 11:57:45] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146130], title[Hi 币乎！], table[article]
[[1;32mSUCC    [0m 04-05 11:57:45] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146130], title[Hi 币乎！]
[[1;32mSUCC    [0m 04-05 11:57:46] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146118], title[]
[[1;32mSUCC    [0m 04-05 11:57:46] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146118], title[], table[article]
[[1;32mSUCC    [0m 04-05 11:57:47] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146118], title[]
[[1;31mERROR   [0m 04-05 11:57:48] [XZLog] [article_week_loop.py:160:parse_item] unkown data structure! artid[146124], raw_str[{"data":null,"res":100004,"resMsg":""}]
[[1;32mSUCC    [0m 04-05 11:57:49] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146125], title[【中国银行：对数字货币监管提出三点建议】]
[[1;32mSUCC    [0m 04-05 11:57:49] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146125], title[【中国银行：对数字货币监管提出三点建议】], table[article]
[[1;32mSUCC    [0m 04-05 11:57:49] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146125], title[【中国银行：对数字货币监管提出三点建议】]
[[1;32mSUCC    [0m 04-05 11:57:51] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146131], title[英国央行希望了解实时总结算服务如何与分布式账本技术进行交互]
[[1;32mSUCC    [0m 04-05 11:57:51] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146131], title[英国央行希望了解实时总结算服务如何与分布式账本技术进行交互], table[article]
[[1;32mSUCC    [0m 04-05 11:57:51] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146131], title[英国央行希望了解实时总结算服务如何与分布式账本技术进行交互]
[[1;32mSUCC    [0m 04-05 11:57:52] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146132], title[对话imtoken，怎样保护你的数字资产！]
[[1;32mSUCC    [0m 04-05 11:57:52] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146132], title[对话imtoken，怎样保护你的数字资产！], table[article]
[[1;32mSUCC    [0m 04-05 11:57:52] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146132], title[对话imtoken，怎样保护你的数字资产！]
[[1;32mSUCC    [0m 04-05 11:57:55] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146133], title[中文资讯网站]
[[1;32mSUCC    [0m 04-05 11:57:55] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146133], title[中文资讯网站], table[article]
[[1;32mSUCC    [0m 04-05 11:57:55] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146133], title[中文资讯网站]
[[1;32mSUCC    [0m 04-05 11:57:56] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146134], title[日本2家数字货币交易所撤销上市申请]
[[1;32mSUCC    [0m 04-05 11:57:56] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146134], title[日本2家数字货币交易所撤销上市申请], table[article]
[[1;32mSUCC    [0m 04-05 11:57:56] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146134], title[日本2家数字货币交易所撤销上市申请]
[[1;32mSUCC    [0m 04-05 11:57:57] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146135], title[]
[[1;32mSUCC    [0m 04-05 11:57:57] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146135], title[], table[article]
[[1;32mSUCC    [0m 04-05 11:57:57] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146135], title[]
[[1;32mSUCC    [0m 04-05 11:57:59] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146136], title[ABIF回应智利交易所“账户被冻结”呼吁:ABIF对解决这一问题没有责任]
[[1;32mSUCC    [0m 04-05 11:57:59] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146136], title[ABIF回应智利交易所“账户被冻结”呼吁:ABIF对解决这一问题没有责任], table[article]
[[1;32mSUCC    [0m 04-05 11:57:59] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146136], title[ABIF回应智利交易所“账户被冻结”呼吁:ABIF对解决这一问题没有责任]
[[1;36mINFO    [0m 04-05 12:05:20] [XZLog] [xzcfg.py:35:__init__] Configure file is /root/bihu24h/config.ini
['/usr/bin', '/usr/lib64/python27.zip', '/usr/lib64/python2.7', '/usr/lib64/python2.7/plat-linux2', '/usr/lib64/python2.7/lib-tk', '/usr/lib64/python2.7/lib-old', '/usr/lib64/python2.7/lib-dynload', '/usr/lib64/python2.7/site-packages', '/usr/lib64/python2.7/site-packages/gtk-2.0', '/usr/lib/python2.7/site-packages', '/root/bihu24h/bihu', '../', '../', '../']
[[1;36mINFO    [0m 04-05 12:05:21] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146257]
==================
set proxy[https://125.104.226.140:40991] artid[146257]
==================
==================
artid[146257] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 12:05:21] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146258]
==================
set proxy[https://125.104.226.140:40991] artid[146258]
==================
==================
artid[146258] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 12:05:21] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146259]
==================
set proxy[https://125.104.226.140:40991] artid[146259]
==================
==================
artid[146259] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 12:05:21] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146260]
==================
set proxy[https://125.104.226.140:40991] artid[146260]
==================
==================
artid[146260] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 12:05:21] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146261]
==================
set proxy[https://125.104.226.140:40991] artid[146261]
==================
==================
artid[146261] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 12:05:21] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146262]
==================
set proxy[https://125.104.226.140:40991] artid[146262]
==================
==================
artid[146262] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 12:05:21] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146263]
==================
set proxy[https://125.104.226.140:40991] artid[146263]
==================
==================
artid[146263] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 12:05:21] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146264]
==================
set proxy[https://125.104.226.140:40991] artid[146264]
==================
==================
artid[146264] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 12:05:21] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146265]
==================
set proxy[https://125.104.226.140:40991] artid[146265]
==================
==================
artid[146265] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 12:05:21] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146266]
==================
set proxy[https://125.104.226.140:40991] artid[146266]
==================
==================
artid[146266] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 12:05:21] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146267]
==================
set proxy[https://125.104.226.140:40991] artid[146267]
==================
==================
artid[146267] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 12:05:21] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146268]
==================
set proxy[https://125.104.226.140:40991] artid[146268]
==================
==================
artid[146268] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 12:05:21] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146269]
==================
set proxy[https://125.104.226.140:40991] artid[146269]
==================
==================
artid[146269] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 12:05:21] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146270]
==================
set proxy[https://125.104.226.140:40991] artid[146270]
==================
==================
artid[146270] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 12:05:21] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146271]
==================
set proxy[https://125.104.226.140:40991] artid[146271]
==================
==================
artid[146271] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 12:05:21] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146272]
==================
set proxy[https://125.104.226.140:40991] artid[146272]
==================
==================
artid[146272] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146257]
==================
==================
artid[146257] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146258]
==================
==================
artid[146258] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146259]
==================
==================
artid[146259] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146260]
==================
==================
artid[146260] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146261]
==================
==================
artid[146261] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146262]
==================
==================
artid[146262] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146263]
==================
==================
artid[146263] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146264]
==================
==================
artid[146264] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146265]
==================
==================
artid[146265] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146266]
==================
==================
artid[146266] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146267]
==================
==================
artid[146267] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146268]
==================
==================
artid[146268] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146269]
==================
==================
artid[146269] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146270]
==================
==================
artid[146270] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146271]
==================
==================
artid[146271] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146272]
==================
==================
artid[146272] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146257]
==================
==================
artid[146257] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146258]
==================
==================
artid[146258] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146259]
==================
==================
artid[146259] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146260]
==================
==================
artid[146260] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146261]
==================
==================
artid[146261] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146262]
==================
==================
artid[146262] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146263]
==================
==================
artid[146263] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146264]
==================
==================
artid[146264] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146265]
==================
==================
artid[146265] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146266]
==================
==================
artid[146266] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146267]
==================
==================
artid[146267] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146268]
==================
==================
artid[146268] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146269]
==================
==================
artid[146269] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146270]
==================
==================
artid[146270] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146271]
==================
==================
artid[146271] proxy_index[1]
==================
==================
set proxy[https://125.104.226.140:40991] artid[146272]
==================
==================
artid[146272] proxy_index[1]
==================
[[1;36mINFO    [0m 04-05 12:06:36] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146273]
==================
set proxy[https://125.104.226.140:40991] artid[146273]
==================
==================
artid[146273] proxy_index[1]
==================
[[1;31mERROR   [0m 04-05 12:06:36] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 12:06:36] [XZLog] [article_week_loop.py:185:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 12:06:37] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
[[1;36mINFO    [0m 04-05 12:06:37] [XZLog] [HttpProxyMiddleware.py:187:invalid_proxy] invalidate {'count': 49, 'valid': True, 'proxy': 'https://125.104.226.140:40991'}
[[1;36mINFO    [0m 04-05 12:06:37] [XZLog] [HttpProxyMiddleware.py:143:inc_proxy_index] now using new proxy: https://202.120.37.202:1080
==================
set proxy[https://202.120.37.202:1080] artid[146257]
==================
==================
artid[146257] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:06:37] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 12:06:37] [XZLog] [article_week_loop.py:185:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 12:06:39] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146258]
==================
==================
artid[146258] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:06:39] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 12:06:39] [XZLog] [article_week_loop.py:185:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 12:06:40] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146259]
==================
==================
artid[146259] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:06:40] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 12:06:40] [XZLog] [article_week_loop.py:185:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 12:06:42] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146260]
==================
==================
artid[146260] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:06:42] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 12:06:42] [XZLog] [article_week_loop.py:185:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 12:06:43] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146261]
==================
==================
artid[146261] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:06:43] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 12:06:43] [XZLog] [article_week_loop.py:185:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 12:06:44] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146262]
==================
==================
artid[146262] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:06:44] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 12:06:44] [XZLog] [article_week_loop.py:185:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 12:06:46] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146263]
==================
==================
artid[146263] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:06:46] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 12:06:46] [XZLog] [article_week_loop.py:185:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 12:06:51] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146264]
==================
==================
artid[146264] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:06:51] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 12:06:51] [XZLog] [article_week_loop.py:185:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 12:06:52] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146265]
==================
==================
artid[146265] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:06:52] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 12:06:52] [XZLog] [article_week_loop.py:185:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 12:06:52] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146266]
==================
==================
artid[146266] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:06:52] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;36mINFO    [0m 04-05 12:06:54] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146274]
==================
set proxy[https://202.120.37.202:1080] artid[146274]
==================
==================
artid[146274] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:06:54] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 12:06:54] [XZLog] [article_week_loop.py:185:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 12:06:54] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146267]
==================
==================
artid[146267] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:06:54] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;36mINFO    [0m 04-05 12:06:55] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146275]
==================
set proxy[https://202.120.37.202:1080] artid[146275]
==================
==================
artid[146275] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 12:06:55] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146276]
==================
set proxy[https://202.120.37.202:1080] artid[146276]
==================
==================
artid[146276] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:06:55] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 12:06:55] [XZLog] [article_week_loop.py:185:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;31mERROR   [0m 04-05 12:06:55] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;36mINFO    [0m 04-05 12:06:56] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146268]
==================
==================
artid[146268] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 12:06:57] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146277]
==================
set proxy[https://202.120.37.202:1080] artid[146277]
==================
==================
artid[146277] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:06:57] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;31mERROR   [0m 04-05 12:06:57] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 12:06:57] [XZLog] [article_week_loop.py:185:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 12:06:58] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146269]
==================
==================
artid[146269] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 12:06:58] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146278]
==================
set proxy[https://202.120.37.202:1080] artid[146278]
==================
==================
artid[146278] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:06:58] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;31mERROR   [0m 04-05 12:06:58] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 12:06:58] [XZLog] [article_week_loop.py:185:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 12:06:59] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146270]
==================
==================
artid[146270] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:06:59] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 12:07:00] [XZLog] [article_week_loop.py:185:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 12:07:00] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146271]
==================
==================
artid[146271] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:07:00] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;36mINFO    [0m 04-05 12:07:01] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146279]
==================
set proxy[https://202.120.37.202:1080] artid[146279]
==================
==================
artid[146279] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:07:01] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;36mINFO    [0m 04-05 12:07:01] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146280]
==================
set proxy[https://202.120.37.202:1080] artid[146280]
==================
==================
artid[146280] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:07:01] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure.>
[[1;33mWARNING [0m 04-05 12:07:01] [XZLog] [article_week_loop.py:185:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 12:07:01] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://202.120.37.202:1080] artid[146272]
==================
==================
artid[146272] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:07:01] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;36mINFO    [0m 04-05 12:07:02] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146281]
==================
set proxy[https://202.120.37.202:1080] artid[146281]
==================
==================
artid[146281] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:07:02] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;36mINFO    [0m 04-05 12:07:03] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146282]
==================
set proxy[https://202.120.37.202:1080] artid[146282]
==================
==================
artid[146282] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:07:03] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://202.120.37.202:1080] artid[146274]
==================
==================
artid[146274] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146273]
==================
==================
artid[146273] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 12:07:06] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146283]
==================
set proxy[https://202.120.37.202:1080] artid[146283]
==================
==================
artid[146283] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:07:06] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://202.120.37.202:1080] artid[146275]
==================
==================
artid[146275] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146276]
==================
==================
artid[146276] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 12:07:09] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146284]
==================
set proxy[https://202.120.37.202:1080] artid[146284]
==================
==================
artid[146284] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:07:09] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://202.120.37.202:1080] artid[146277]
==================
==================
artid[146277] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 12:07:12] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146285]
==================
set proxy[https://202.120.37.202:1080] artid[146285]
==================
==================
artid[146285] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:07:12] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://202.120.37.202:1080] artid[146278]
==================
==================
artid[146278] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 12:07:14] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146286]
==================
set proxy[https://202.120.37.202:1080] artid[146286]
==================
==================
artid[146286] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:07:14] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;36mINFO    [0m 04-05 12:07:14] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146287]
==================
set proxy[https://202.120.37.202:1080] artid[146287]
==================
==================
artid[146287] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:07:14] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://202.120.37.202:1080] artid[146279]
==================
==================
artid[146279] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146280]
==================
==================
artid[146280] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 12:07:18] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146288]
==================
set proxy[https://202.120.37.202:1080] artid[146288]
==================
==================
artid[146288] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:07:18] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://202.120.37.202:1080] artid[146281]
==================
==================
artid[146281] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146282]
==================
==================
artid[146282] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146274]
==================
==================
artid[146274] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146273]
==================
==================
artid[146273] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146283]
==================
==================
artid[146283] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146275]
==================
==================
artid[146275] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146276]
==================
==================
artid[146276] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146284]
==================
==================
artid[146284] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146277]
==================
==================
artid[146277] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146285]
==================
==================
artid[146285] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146278]
==================
==================
artid[146278] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146286]
==================
==================
artid[146286] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146287]
==================
==================
artid[146287] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146279]
==================
==================
artid[146279] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146280]
==================
==================
artid[146280] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146288]
==================
==================
artid[146288] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146281]
==================
==================
artid[146281] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146282]
==================
==================
artid[146282] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 12:07:41] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146289]
==================
set proxy[https://202.120.37.202:1080] artid[146289]
==================
==================
artid[146289] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:07:42] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;36mINFO    [0m 04-05 12:07:43] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146290]
==================
set proxy[https://202.120.37.202:1080] artid[146290]
==================
==================
artid[146290] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:07:43] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://202.120.37.202:1080] artid[146283]
==================
==================
artid[146283] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 12:07:45] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146291]
==================
set proxy[https://202.120.37.202:1080] artid[146291]
==================
==================
artid[146291] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:07:45] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;36mINFO    [0m 04-05 12:07:46] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146292]
==================
set proxy[https://202.120.37.202:1080] artid[146292]
==================
==================
artid[146292] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:07:47] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://202.120.37.202:1080] artid[146284]
==================
==================
artid[146284] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 12:07:49] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146293]
==================
set proxy[https://202.120.37.202:1080] artid[146293]
==================
==================
artid[146293] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:07:49] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://202.120.37.202:1080] artid[146285]
==================
==================
artid[146285] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 12:07:52] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146294]
==================
set proxy[https://202.120.37.202:1080] artid[146294]
==================
==================
artid[146294] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:07:52] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://202.120.37.202:1080] artid[146286]
==================
==================
artid[146286] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146287]
==================
==================
artid[146287] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146288]
==================
==================
artid[146288] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 12:07:59] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146295]
==================
set proxy[https://202.120.37.202:1080] artid[146295]
==================
==================
artid[146295] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:08:00] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;36mINFO    [0m 04-05 12:08:00] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146296]
==================
set proxy[https://202.120.37.202:1080] artid[146296]
==================
==================
artid[146296] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:08:00] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://202.120.37.202:1080] artid[146289]
==================
==================
artid[146289] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146290]
==================
==================
artid[146290] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146291]
==================
==================
artid[146291] proxy_index[2]
==================
==================
set proxy[https://202.120.37.202:1080] artid[146292]
==================
==================
artid[146292] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 12:08:09] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146297]
==================
set proxy[https://202.120.37.202:1080] artid[146297]
==================
==================
artid[146297] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:08:09] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://202.120.37.202:1080] artid[146293]
==================
==================
artid[146293] proxy_index[2]
==================
[[1;36mINFO    [0m 04-05 12:08:10] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146298]
==================
set proxy[https://202.120.37.202:1080] artid[146298]
==================
==================
artid[146298] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:08:10] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;36mINFO    [0m 04-05 12:08:10] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146299]
==================
set proxy[https://202.120.37.202:1080] artid[146299]
==================
==================
artid[146299] proxy_index[2]
==================
[[1;31mERROR   [0m 04-05 12:08:10] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://be02.bihu.com/bihube-pc/api/content/show/getArticle took longer than 15.0 seconds..>
[[1;33mWARNING [0m 04-05 12:08:10] [XZLog] [article_week_loop.py:185:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 12:08:12] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
[[1;36mINFO    [0m 04-05 12:08:12] [XZLog] [HttpProxyMiddleware.py:187:invalid_proxy] invalidate {'count': 79, 'valid': True, 'proxy': 'https://202.120.37.202:1080'}
[[1;36mINFO    [0m 04-05 12:08:12] [XZLog] [HttpProxyMiddleware.py:143:inc_proxy_index] now using new proxy: https://120.92.118.64:10010
==================
set proxy[https://120.92.118.64:10010] artid[146279]
==================
==================
artid[146279] proxy_index[3]
==================
[[1;31mERROR   [0m 04-05 12:08:12] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://be02.bihu.com/bihube-pc/api/content/show/getArticle took longer than 15.0 seconds..>
[[1;33mWARNING [0m 04-05 12:08:12] [XZLog] [article_week_loop.py:185:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 12:08:12] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://120.92.118.64:10010] artid[146280]
==================
==================
artid[146280] proxy_index[3]
==================
[[1;31mERROR   [0m 04-05 12:08:12] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;36mINFO    [0m 04-05 12:08:13] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146300]
==================
set proxy[https://120.92.118.64:10010] artid[146300]
==================
==================
artid[146300] proxy_index[3]
==================
[[1;31mERROR   [0m 04-05 12:08:13] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
[[1;36mINFO    [0m 04-05 12:08:14] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146301]
==================
set proxy[https://120.92.118.64:10010] artid[146301]
==================
==================
artid[146301] proxy_index[3]
==================
[[1;31mERROR   [0m 04-05 12:08:14] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure scrapy.core.downloader.handlers.http11.TunnelError: Could not open CONNECT tunnel with proxy 202.120.37.202:1080 [{'status': 503, 'reason': bytearray(b'Too many open connections')}]>
==================
set proxy[https://120.92.118.64:10010] artid[146295]
==================
==================
artid[146295] proxy_index[3]
==================
==================
set proxy[https://120.92.118.64:10010] artid[146289]
==================
==================
artid[146289] proxy_index[3]
==================
==================
set proxy[https://120.92.118.64:10010] artid[146290]
==================
==================
artid[146290] proxy_index[3]
==================
[[1;36mINFO    [0m 04-05 12:08:19] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146302]
==================
set proxy[https://120.92.118.64:10010] artid[146302]
==================
==================
artid[146302] proxy_index[3]
==================
[[1;31mERROR   [0m 04-05 12:08:19] [XZLog] [article_week_loop.py:168:parse_errback] <twisted.python.failure.Failure twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://be02.bihu.com/bihube-pc/api/content/show/getArticle took longer than 15.0 seconds..>
[[1;33mWARNING [0m 04-05 12:08:19] [XZLog] [article_week_loop.py:185:parse_errback] Change proxy and re-request due to TimeoutError on https://be02.bihu.com/bihube-pc/api/content/show/getArticle
[[1;36mINFO    [0m 04-05 12:08:20] [XZLog] [HttpProxyMiddleware.py:221:process_request] change proxy request get by spider: <POST https://be02.bihu.com/bihube-pc/api/content/show/getArticle>
==================
set proxy[https://120.92.118.64:10010] artid[146283]
==================
==================
artid[146283] proxy_index[3]
==================
==================
set proxy[https://120.92.118.64:10010] artid[146292]
==================
==================
artid[146292] proxy_index[3]
==================
==================
set proxy[https://120.92.118.64:10010] artid[146297]
==================
==================
artid[146297] proxy_index[3]
==================
==================
set proxy[https://120.92.118.64:10010] artid[146293]
==================
==================
artid[146293] proxy_index[3]
==================
==================
set proxy[https://120.92.118.64:10010] artid[146294]
==================
==================
artid[146294] proxy_index[3]
==================
==================
set proxy[https://120.92.118.64:10010] artid[146299]
==================
==================
artid[146299] proxy_index[3]
==================
==================
set proxy[https://120.92.118.64:10010] artid[146291]
==================
==================
artid[146291] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:08:29] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146279], title[Gift.ONE正在空投Token！ 目前1GIFT = US$0.2，注册即送100GIFT]
[[1;32mSUCC    [0m 04-05 12:08:29] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146279], title[Gift.ONE正在空投Token！ 目前1GIFT = US$0.2，注册即送100GIFT], table[article]
[[1;32mSUCC    [0m 04-05 12:08:29] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146279], title[Gift.ONE正在空投Token！ 目前1GIFT = US$0.2，注册即送100GIFT]
[[1;36mINFO    [0m 04-05 12:08:29] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146303]
==================
set proxy[https://120.92.118.64:10010] artid[146303]
==================
==================
artid[146303] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:08:30] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146280], title[中高会区块链产业联盟朱涛：区块链本质是技术，要关在“笼子”里]
[[1;32mSUCC    [0m 04-05 12:08:30] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146280], title[中高会区块链产业联盟朱涛：区块链本质是技术，要关在“笼子”里], table[article]
[[1;32mSUCC    [0m 04-05 12:08:30] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146280], title[中高会区块链产业联盟朱涛：区块链本质是技术，要关在“笼子”里]
[[1;36mINFO    [0m 04-05 12:08:31] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146304]
==================
set proxy[https://120.92.118.64:10010] artid[146304]
==================
==================
artid[146304] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:08:31] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146300], title[还有多少人不知道币乎]
[[1;32mSUCC    [0m 04-05 12:08:31] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146300], title[还有多少人不知道币乎], table[article]
[[1;32mSUCC    [0m 04-05 12:08:31] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146300], title[还有多少人不知道币乎]
==================
set proxy[https://120.92.118.64:10010] artid[146296]
==================
==================
artid[146296] proxy_index[3]
==================
[[1;36mINFO    [0m 04-05 12:08:32] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146305]
==================
set proxy[https://120.92.118.64:10010] artid[146305]
==================
==================
artid[146305] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:08:32] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146301], title[]
[[1;32mSUCC    [0m 04-05 12:08:32] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146301], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:08:32] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146301], title[]
[[1;36mINFO    [0m 04-05 12:08:33] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146306]
==================
set proxy[https://120.92.118.64:10010] artid[146306]
==================
==================
artid[146306] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:08:33] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146295], title[]
[[1;32mSUCC    [0m 04-05 12:08:33] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146295], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:08:33] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146295], title[]
[[1;36mINFO    [0m 04-05 12:08:35] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146307]
==================
set proxy[https://120.92.118.64:10010] artid[146307]
==================
==================
artid[146307] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:08:35] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146289], title[]
[[1;32mSUCC    [0m 04-05 12:08:35] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146289], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:08:35] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146289], title[]
[[1;36mINFO    [0m 04-05 12:08:36] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146308]
==================
set proxy[https://120.92.118.64:10010] artid[146308]
==================
==================
artid[146308] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:08:36] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146290], title[]
[[1;32mSUCC    [0m 04-05 12:08:36] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146290], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:08:36] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146290], title[]
[[1;36mINFO    [0m 04-05 12:08:37] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146309]
==================
set proxy[https://120.92.118.64:10010] artid[146309]
==================
==================
artid[146309] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:08:37] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146302], title[休息一下，一休哥！]
[[1;32mSUCC    [0m 04-05 12:08:37] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146302], title[休息一下，一休哥！], table[article]
[[1;32mSUCC    [0m 04-05 12:08:37] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146302], title[休息一下，一休哥！]
[[1;36mINFO    [0m 04-05 12:08:39] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146310]
==================
set proxy[https://120.92.118.64:10010] artid[146310]
==================
==================
artid[146310] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:08:39] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146283], title[]
[[1;32mSUCC    [0m 04-05 12:08:39] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146283], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:08:39] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146283], title[]
[[1;36mINFO    [0m 04-05 12:08:40] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146311]
==================
set proxy[https://120.92.118.64:10010] artid[146311]
==================
==================
artid[146311] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:08:40] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146292], title[]
[[1;32mSUCC    [0m 04-05 12:08:40] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146292], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:08:40] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146292], title[]
==================
set proxy[https://120.92.118.64:10010] artid[146298]
==================
==================
artid[146298] proxy_index[3]
==================
[[1;36mINFO    [0m 04-05 12:08:41] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146312]
==================
set proxy[https://120.92.118.64:10010] artid[146312]
==================
==================
artid[146312] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:08:41] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146297], title[]
[[1;32mSUCC    [0m 04-05 12:08:41] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146297], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:08:41] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146297], title[]
[[1;36mINFO    [0m 04-05 12:08:42] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146313]
==================
set proxy[https://120.92.118.64:10010] artid[146313]
==================
==================
artid[146313] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:08:42] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146293], title[区块链保险联盟B3i宣布转型成立独立公司]
[[1;32mSUCC    [0m 04-05 12:08:42] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146293], title[区块链保险联盟B3i宣布转型成立独立公司], table[article]
[[1;32mSUCC    [0m 04-05 12:08:42] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146293], title[区块链保险联盟B3i宣布转型成立独立公司]
[[1;36mINFO    [0m 04-05 12:08:43] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146314]
==================
set proxy[https://120.92.118.64:10010] artid[146314]
==================
==================
artid[146314] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:08:44] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146294], title[币圈搬砖常用网站收集]
[[1;32mSUCC    [0m 04-05 12:08:44] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146294], title[币圈搬砖常用网站收集], table[article]
[[1;32mSUCC    [0m 04-05 12:08:44] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146294], title[币圈搬砖常用网站收集]
[[1;36mINFO    [0m 04-05 12:08:45] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146315]
==================
set proxy[https://120.92.118.64:10010] artid[146315]
==================
==================
artid[146315] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:08:45] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146299], title[]
[[1;32mSUCC    [0m 04-05 12:08:45] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146299], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:08:45] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146299], title[]
[[1;36mINFO    [0m 04-05 12:08:46] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146316]
==================
set proxy[https://120.92.118.64:10010] artid[146316]
==================
==================
artid[146316] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:08:46] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146291], title[正解]
[[1;32mSUCC    [0m 04-05 12:08:46] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146291], title[正解], table[article]
[[1;32mSUCC    [0m 04-05 12:08:46] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146291], title[正解]
[[1;36mINFO    [0m 04-05 12:08:47] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146317]
==================
set proxy[https://120.92.118.64:10010] artid[146317]
==================
==================
artid[146317] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:08:47] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146303], title[21家公司探路区块链+金融，四大领域迎来巨大机遇]
[[1;32mSUCC    [0m 04-05 12:08:48] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146303], title[21家公司探路区块链+金融，四大领域迎来巨大机遇], table[article]
[[1;32mSUCC    [0m 04-05 12:08:48] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146303], title[21家公司探路区块链+金融，四大领域迎来巨大机遇]
[[1;36mINFO    [0m 04-05 12:08:49] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146318]
==================
set proxy[https://120.92.118.64:10010] artid[146318]
==================
==================
artid[146318] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:08:49] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146304], title[2018年ETC价格猛涨几大因素分析(转载)]
[[1;32mSUCC    [0m 04-05 12:08:49] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146304], title[2018年ETC价格猛涨几大因素分析(转载)], table[article]
[[1;32mSUCC    [0m 04-05 12:08:49] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146304], title[2018年ETC价格猛涨几大因素分析(转载)]
[[1;36mINFO    [0m 04-05 12:08:50] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146319]
==================
set proxy[https://120.92.118.64:10010] artid[146319]
==================
==================
artid[146319] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:08:50] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146296], title[]
[[1;32mSUCC    [0m 04-05 12:08:50] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146296], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:08:50] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146296], title[]
[[1;36mINFO    [0m 04-05 12:08:52] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146320]
==================
set proxy[https://120.92.118.64:10010] artid[146320]
==================
==================
artid[146320] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:08:52] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146305], title[我们为什么要读书和终生学习？【转载分享】]
[[1;32mSUCC    [0m 04-05 12:08:52] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146305], title[我们为什么要读书和终生学习？【转载分享】], table[article]
[[1;32mSUCC    [0m 04-05 12:08:52] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146305], title[我们为什么要读书和终生学习？【转载分享】]
[[1;36mINFO    [0m 04-05 12:08:53] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146321]
==================
set proxy[https://120.92.118.64:10010] artid[146321]
==================
==================
artid[146321] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:08:53] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146306], title[如何用微信购买比特币？]
[[1;32mSUCC    [0m 04-05 12:08:53] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146306], title[如何用微信购买比特币？], table[article]
[[1;32mSUCC    [0m 04-05 12:08:53] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146306], title[如何用微信购买比特币？]
[[1;36mINFO    [0m 04-05 12:08:54] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146322]
==================
set proxy[https://120.92.118.64:10010] artid[146322]
==================
==================
artid[146322] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:08:54] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146307], title[]
[[1;32mSUCC    [0m 04-05 12:08:54] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146307], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:08:54] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146307], title[]
[[1;36mINFO    [0m 04-05 12:08:55] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146323]
==================
set proxy[https://120.92.118.64:10010] artid[146323]
==================
==================
artid[146323] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:08:56] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146308], title[]
[[1;32mSUCC    [0m 04-05 12:08:56] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146308], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:08:56] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146308], title[]
[[1;36mINFO    [0m 04-05 12:08:57] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146324]
==================
set proxy[https://120.92.118.64:10010] artid[146324]
==================
==================
artid[146324] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:08:57] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146309], title[除了比特币，区块链还能干点啥]
[[1;32mSUCC    [0m 04-05 12:08:57] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146309], title[除了比特币，区块链还能干点啥], table[article]
[[1;32mSUCC    [0m 04-05 12:08:57] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146309], title[除了比特币，区块链还能干点啥]
[[1;36mINFO    [0m 04-05 12:08:58] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146325]
==================
set proxy[https://120.92.118.64:10010] artid[146325]
==================
==================
artid[146325] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:08:58] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146310], title[【3.29币圈新闻总汇】]
[[1;32mSUCC    [0m 04-05 12:08:58] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146310], title[【3.29币圈新闻总汇】], table[article]
[[1;32mSUCC    [0m 04-05 12:08:58] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146310], title[【3.29币圈新闻总汇】]
[[1;36mINFO    [0m 04-05 12:09:00] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146326]
==================
set proxy[https://120.92.118.64:10010] artid[146326]
==================
==================
artid[146326] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:00] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146311], title[关于区块链的9个问答：行业爆发点与识别骗局]
[[1;32mSUCC    [0m 04-05 12:09:00] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146311], title[关于区块链的9个问答：行业爆发点与识别骗局], table[article]
[[1;32mSUCC    [0m 04-05 12:09:00] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146311], title[关于区块链的9个问答：行业爆发点与识别骗局]
[[1;36mINFO    [0m 04-05 12:09:01] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146327]
==================
set proxy[https://120.92.118.64:10010] artid[146327]
==================
==================
artid[146327] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:01] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146298], title[【下篇】千亿利润下的EOS争霸]
[[1;32mSUCC    [0m 04-05 12:09:01] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146298], title[【下篇】千亿利润下的EOS争霸], table[article]
[[1;32mSUCC    [0m 04-05 12:09:01] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146298], title[【下篇】千亿利润下的EOS争霸]
[[1;36mINFO    [0m 04-05 12:09:02] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146328]
==================
set proxy[https://120.92.118.64:10010] artid[146328]
==================
==================
artid[146328] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:02] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146312], title[币问正式对接YOYOW自动激励功能，YOYOW正式落地第一站]
[[1;32mSUCC    [0m 04-05 12:09:02] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146312], title[币问正式对接YOYOW自动激励功能，YOYOW正式落地第一站], table[article]
[[1;32mSUCC    [0m 04-05 12:09:02] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146312], title[币问正式对接YOYOW自动激励功能，YOYOW正式落地第一站]
[[1;36mINFO    [0m 04-05 12:09:03] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146329]
==================
set proxy[https://120.92.118.64:10010] artid[146329]
==================
==================
artid[146329] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:03] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146313], title[万链之家-中国版数字货币最全介绍!]
[[1;32mSUCC    [0m 04-05 12:09:03] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146313], title[万链之家-中国版数字货币最全介绍!], table[article]
[[1;32mSUCC    [0m 04-05 12:09:03] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146313], title[万链之家-中国版数字货币最全介绍!]
[[1;36mINFO    [0m 04-05 12:09:04] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146330]
==================
set proxy[https://120.92.118.64:10010] artid[146330]
==================
==================
artid[146330] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:05] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146314], title[]
[[1;32mSUCC    [0m 04-05 12:09:05] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146314], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:09:05] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146314], title[]
[[1;36mINFO    [0m 04-05 12:09:05] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146331]
==================
set proxy[https://120.92.118.64:10010] artid[146331]
==================
==================
artid[146331] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:06] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146315], title[]
[[1;32mSUCC    [0m 04-05 12:09:06] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146315], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:09:06] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146315], title[]
[[1;36mINFO    [0m 04-05 12:09:07] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146332]
==================
set proxy[https://120.92.118.64:10010] artid[146332]
==================
==================
artid[146332] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:07] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146316], title[币圈故事——“泡沫”之夏（一）]
[[1;32mSUCC    [0m 04-05 12:09:07] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146316], title[币圈故事——“泡沫”之夏（一）], table[article]
[[1;32mSUCC    [0m 04-05 12:09:07] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146316], title[币圈故事——“泡沫”之夏（一）]
[[1;36mINFO    [0m 04-05 12:09:08] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146333]
==================
set proxy[https://120.92.118.64:10010] artid[146333]
==================
==================
artid[146333] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:08] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146317], title[比特币诞生]
[[1;32mSUCC    [0m 04-05 12:09:08] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146317], title[比特币诞生], table[article]
[[1;32mSUCC    [0m 04-05 12:09:08] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146317], title[比特币诞生]
[[1;36mINFO    [0m 04-05 12:09:08] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146334]
==================
set proxy[https://120.92.118.64:10010] artid[146334]
==================
==================
artid[146334] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:09] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146318], title[]
[[1;32mSUCC    [0m 04-05 12:09:09] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146318], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:09:09] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146318], title[]
[[1;36mINFO    [0m 04-05 12:09:10] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146335]
==================
set proxy[https://120.92.118.64:10010] artid[146335]
==================
==================
artid[146335] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:10] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146319], title[币圈故事——“泡沫”之夏（二）]
[[1;32mSUCC    [0m 04-05 12:09:10] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146319], title[币圈故事——“泡沫”之夏（二）], table[article]
[[1;32mSUCC    [0m 04-05 12:09:10] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146319], title[币圈故事——“泡沫”之夏（二）]
[[1;36mINFO    [0m 04-05 12:09:10] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146336]
==================
set proxy[https://120.92.118.64:10010] artid[146336]
==================
==================
artid[146336] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:10] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146320], title[币世风云录]
[[1;32mSUCC    [0m 04-05 12:09:10] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146320], title[币世风云录], table[article]
[[1;32mSUCC    [0m 04-05 12:09:10] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146320], title[币世风云录]
[[1;36mINFO    [0m 04-05 12:09:12] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146337]
==================
set proxy[https://120.92.118.64:10010] artid[146337]
==================
==================
artid[146337] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:12] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146321], title[备受质疑的区块链，为什么是绝无仅有的“造富”机会？]
[[1;32mSUCC    [0m 04-05 12:09:12] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146321], title[备受质疑的区块链，为什么是绝无仅有的“造富”机会？], table[article]
[[1;32mSUCC    [0m 04-05 12:09:12] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146321], title[备受质疑的区块链，为什么是绝无仅有的“造富”机会？]
[[1;36mINFO    [0m 04-05 12:09:13] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146338]
==================
set proxy[https://120.92.118.64:10010] artid[146338]
==================
==================
artid[146338] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:13] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146322], title[投资币市可以一夜暴富吗？]
[[1;32mSUCC    [0m 04-05 12:09:13] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146322], title[投资币市可以一夜暴富吗？], table[article]
[[1;32mSUCC    [0m 04-05 12:09:13] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146322], title[投资币市可以一夜暴富吗？]
[[1;36mINFO    [0m 04-05 12:09:14] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146339]
==================
set proxy[https://120.92.118.64:10010] artid[146339]
==================
==================
artid[146339] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:14] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146323], title[新人报道]
[[1;32mSUCC    [0m 04-05 12:09:14] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146323], title[新人报道], table[article]
[[1;32mSUCC    [0m 04-05 12:09:14] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146323], title[新人报道]
[[1;36mINFO    [0m 04-05 12:09:15] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146340]
==================
set proxy[https://120.92.118.64:10010] artid[146340]
==================
==================
artid[146340] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:15] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146324], title[]
[[1;32mSUCC    [0m 04-05 12:09:15] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146324], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:09:15] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146324], title[]
[[1;36mINFO    [0m 04-05 12:09:16] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146341]
==================
set proxy[https://120.92.118.64:10010] artid[146341]
==================
==================
artid[146341] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:16] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146325], title[币乎成长录9:长铗大佬理解的区块链思维2]
[[1;32mSUCC    [0m 04-05 12:09:16] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146325], title[币乎成长录9:长铗大佬理解的区块链思维2], table[article]
[[1;32mSUCC    [0m 04-05 12:09:16] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146325], title[币乎成长录9:长铗大佬理解的区块链思维2]
[[1;36mINFO    [0m 04-05 12:09:17] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146342]
==================
set proxy[https://120.92.118.64:10010] artid[146342]
==================
==================
artid[146342] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:17] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146326], title[领取Nucleus代币]
[[1;32mSUCC    [0m 04-05 12:09:17] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146326], title[领取Nucleus代币], table[article]
[[1;32mSUCC    [0m 04-05 12:09:17] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146326], title[领取Nucleus代币]
[[1;36mINFO    [0m 04-05 12:09:18] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146343]
==================
set proxy[https://120.92.118.64:10010] artid[146343]
==================
==================
artid[146343] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:18] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146327], title[]
[[1;32mSUCC    [0m 04-05 12:09:18] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146327], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:09:18] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146327], title[]
[[1;36mINFO    [0m 04-05 12:09:19] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146344]
==================
set proxy[https://120.92.118.64:10010] artid[146344]
==================
==================
artid[146344] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:19] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146328], title[]
[[1;32mSUCC    [0m 04-05 12:09:20] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146328], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:09:20] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146328], title[]
[[1;36mINFO    [0m 04-05 12:09:20] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146345]
==================
set proxy[https://120.92.118.64:10010] artid[146345]
==================
==================
artid[146345] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:21] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146329], title[维基链欲切入多个应用，能否成为区块链应用的“独角兽”呢?]
[[1;32mSUCC    [0m 04-05 12:09:21] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146329], title[维基链欲切入多个应用，能否成为区块链应用的“独角兽”呢?], table[article]
[[1;32mSUCC    [0m 04-05 12:09:21] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146329], title[维基链欲切入多个应用，能否成为区块链应用的“独角兽”呢?]
[[1;36mINFO    [0m 04-05 12:09:22] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146346]
==================
set proxy[https://120.92.118.64:10010] artid[146346]
==================
==================
artid[146346] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:22] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146330], title[区块链：信息的演化进程]
[[1;32mSUCC    [0m 04-05 12:09:22] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146330], title[区块链：信息的演化进程], table[article]
[[1;32mSUCC    [0m 04-05 12:09:22] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146330], title[区块链：信息的演化进程]
[[1;36mINFO    [0m 04-05 12:09:23] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146347]
==================
set proxy[https://120.92.118.64:10010] artid[146347]
==================
==================
artid[146347] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:23] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146331], title[]
[[1;32mSUCC    [0m 04-05 12:09:23] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146331], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:09:23] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146331], title[]
[[1;36mINFO    [0m 04-05 12:09:24] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146348]
==================
set proxy[https://120.92.118.64:10010] artid[146348]
==================
==================
artid[146348] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:24] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146332], title[好韭上线]
[[1;32mSUCC    [0m 04-05 12:09:24] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146332], title[好韭上线], table[article]
[[1;32mSUCC    [0m 04-05 12:09:25] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146332], title[好韭上线]
[[1;36mINFO    [0m 04-05 12:09:26] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146349]
==================
set proxy[https://120.92.118.64:10010] artid[146349]
==================
==================
artid[146349] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:26] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146333], title[币乎游戏--充值得顶级装备！你来币乎做什么？？（1）！--写给与比特币擦肩而过的自己]
[[1;32mSUCC    [0m 04-05 12:09:26] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146333], title[币乎游戏--充值得顶级装备！你来币乎做什么？？（1）！--写给与比特币擦肩而过的自己], table[article]
[[1;32mSUCC    [0m 04-05 12:09:26] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146333], title[币乎游戏--充值得顶级装备！你来币乎做什么？？（1）！--写给与比特币擦肩而过的自己]
[[1;36mINFO    [0m 04-05 12:09:27] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146350]
==================
set proxy[https://120.92.118.64:10010] artid[146350]
==================
==================
artid[146350] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:27] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146334], title[]
[[1;32mSUCC    [0m 04-05 12:09:27] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146334], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:09:27] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146334], title[]
[[1;36mINFO    [0m 04-05 12:09:29] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146351]
==================
set proxy[https://120.92.118.64:10010] artid[146351]
==================
==================
artid[146351] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:29] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146335], title[我们是否该像机器人点赞妥协？]
[[1;32mSUCC    [0m 04-05 12:09:29] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146335], title[我们是否该像机器人点赞妥协？], table[article]
[[1;32mSUCC    [0m 04-05 12:09:29] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146335], title[我们是否该像机器人点赞妥协？]
[[1;36mINFO    [0m 04-05 12:09:30] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146352]
==================
set proxy[https://120.92.118.64:10010] artid[146352]
==================
==================
artid[146352] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:30] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146336], title[浅谈对eth的看法]
[[1;32mSUCC    [0m 04-05 12:09:30] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146336], title[浅谈对eth的看法], table[article]
[[1;32mSUCC    [0m 04-05 12:09:30] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146336], title[浅谈对eth的看法]
[[1;36mINFO    [0m 04-05 12:09:30] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146353]
==================
set proxy[https://120.92.118.64:10010] artid[146353]
==================
==================
artid[146353] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:31] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146337], title[晚餐-决定你的格局]
[[1;32mSUCC    [0m 04-05 12:09:31] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146337], title[晚餐-决定你的格局], table[article]
[[1;32mSUCC    [0m 04-05 12:09:31] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146337], title[晚餐-决定你的格局]
[[1;36mINFO    [0m 04-05 12:09:32] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146354]
==================
set proxy[https://120.92.118.64:10010] artid[146354]
==================
==================
artid[146354] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:32] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146338], title[]
[[1;32mSUCC    [0m 04-05 12:09:32] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146338], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:09:32] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146338], title[]
[[1;36mINFO    [0m 04-05 12:09:33] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146355]
==================
set proxy[https://120.92.118.64:10010] artid[146355]
==================
==================
artid[146355] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:33] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146339], title[凤凰网上线区块链产品“凤凰蛋”]
[[1;32mSUCC    [0m 04-05 12:09:33] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146339], title[凤凰网上线区块链产品“凤凰蛋”], table[article]
[[1;32mSUCC    [0m 04-05 12:09:33] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146339], title[凤凰网上线区块链产品“凤凰蛋”]
[[1;36mINFO    [0m 04-05 12:09:34] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146356]
==================
set proxy[https://120.92.118.64:10010] artid[146356]
==================
==================
artid[146356] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:34] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146340], title[应用│区块链技术是如何改变医疗领域的?]
[[1;32mSUCC    [0m 04-05 12:09:35] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146340], title[应用│区块链技术是如何改变医疗领域的?], table[article]
[[1;32mSUCC    [0m 04-05 12:09:35] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146340], title[应用│区块链技术是如何改变医疗领域的?]
[[1;36mINFO    [0m 04-05 12:09:36] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146357]
==================
set proxy[https://120.92.118.64:10010] artid[146357]
==================
==================
artid[146357] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:36] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146341], title[币圈一天，人间一年]
[[1;32mSUCC    [0m 04-05 12:09:36] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146341], title[币圈一天，人间一年], table[article]
[[1;32mSUCC    [0m 04-05 12:09:36] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146341], title[币圈一天，人间一年]
[[1;36mINFO    [0m 04-05 12:09:36] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146358]
==================
set proxy[https://120.92.118.64:10010] artid[146358]
==================
==================
artid[146358] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:36] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146342], title[虚拟货币的特殊点]
[[1;32mSUCC    [0m 04-05 12:09:36] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146342], title[虚拟货币的特殊点], table[article]
[[1;32mSUCC    [0m 04-05 12:09:36] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146342], title[虚拟货币的特殊点]
[[1;36mINFO    [0m 04-05 12:09:37] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146359]
==================
set proxy[https://120.92.118.64:10010] artid[146359]
==================
==================
artid[146359] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:37] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146343], title[比特币(BTC)晚间更新:横向价格动作意味着对称三角形。]
[[1;32mSUCC    [0m 04-05 12:09:37] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146343], title[比特币(BTC)晚间更新:横向价格动作意味着对称三角形。], table[article]
[[1;32mSUCC    [0m 04-05 12:09:37] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146343], title[比特币(BTC)晚间更新:横向价格动作意味着对称三角形。]
[[1;36mINFO    [0m 04-05 12:09:39] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146360]
==================
set proxy[https://120.92.118.64:10010] artid[146360]
==================
==================
artid[146360] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:39] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146344], title[你知道吗]
[[1;32mSUCC    [0m 04-05 12:09:39] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146344], title[你知道吗], table[article]
[[1;32mSUCC    [0m 04-05 12:09:39] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146344], title[你知道吗]
[[1;36mINFO    [0m 04-05 12:09:40] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146361]
==================
set proxy[https://120.92.118.64:10010] artid[146361]
==================
==================
artid[146361] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:40] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146345], title[区块链简明生存指南]
[[1;32mSUCC    [0m 04-05 12:09:40] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146345], title[区块链简明生存指南], table[article]
[[1;32mSUCC    [0m 04-05 12:09:40] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146345], title[区块链简明生存指南]
[[1;36mINFO    [0m 04-05 12:09:41] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146362]
==================
set proxy[https://120.92.118.64:10010] artid[146362]
==================
==================
artid[146362] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:41] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146346], title[]
[[1;32mSUCC    [0m 04-05 12:09:41] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146346], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:09:41] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146346], title[]
[[1;36mINFO    [0m 04-05 12:09:43] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146363]
==================
set proxy[https://120.92.118.64:10010] artid[146363]
==================
==================
artid[146363] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:43] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146347], title[【每日热聊榜】辞职炒币是种怎样的体验？]
[[1;32mSUCC    [0m 04-05 12:09:43] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146347], title[【每日热聊榜】辞职炒币是种怎样的体验？], table[article]
[[1;32mSUCC    [0m 04-05 12:09:43] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146347], title[【每日热聊榜】辞职炒币是种怎样的体验？]
[[1;36mINFO    [0m 04-05 12:09:44] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146364]
==================
set proxy[https://120.92.118.64:10010] artid[146364]
==================
==================
artid[146364] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:44] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146348], title[政策消息]
[[1;32mSUCC    [0m 04-05 12:09:44] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146348], title[政策消息], table[article]
[[1;32mSUCC    [0m 04-05 12:09:44] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146348], title[政策消息]
[[1;36mINFO    [0m 04-05 12:09:45] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146365]
==================
set proxy[https://120.92.118.64:10010] artid[146365]
==================
==================
artid[146365] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:45] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146349], title[白俄罗斯物尽其用]
[[1;32mSUCC    [0m 04-05 12:09:45] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146349], title[白俄罗斯物尽其用], table[article]
[[1;32mSUCC    [0m 04-05 12:09:45] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146349], title[白俄罗斯物尽其用]
[[1;36mINFO    [0m 04-05 12:09:47] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146366]
==================
set proxy[https://120.92.118.64:10010] artid[146366]
==================
==================
artid[146366] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:47] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146350], title[驴克思每日精读2018-3-29:越跌越买]
[[1;32mSUCC    [0m 04-05 12:09:47] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146350], title[驴克思每日精读2018-3-29:越跌越买], table[article]
[[1;32mSUCC    [0m 04-05 12:09:47] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146350], title[驴克思每日精读2018-3-29:越跌越买]
[[1;36mINFO    [0m 04-05 12:09:47] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146367]
==================
set proxy[https://120.92.118.64:10010] artid[146367]
==================
==================
artid[146367] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:48] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146351], title[]
[[1;32mSUCC    [0m 04-05 12:09:48] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146351], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:09:48] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146351], title[]
[[1;36mINFO    [0m 04-05 12:09:49] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146368]
==================
set proxy[https://120.92.118.64:10010] artid[146368]
==================
==================
artid[146368] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:49] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146352], title[]
[[1;32mSUCC    [0m 04-05 12:09:49] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146352], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:09:49] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146352], title[]
[[1;36mINFO    [0m 04-05 12:09:50] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146369]
==================
set proxy[https://120.92.118.64:10010] artid[146369]
==================
==================
artid[146369] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:50] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146353], title[TenX的前CFO已加入LiveEdu]
[[1;32mSUCC    [0m 04-05 12:09:50] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146353], title[TenX的前CFO已加入LiveEdu], table[article]
[[1;32mSUCC    [0m 04-05 12:09:50] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146353], title[TenX的前CFO已加入LiveEdu]
[[1;36mINFO    [0m 04-05 12:09:51] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146370]
==================
set proxy[https://120.92.118.64:10010] artid[146370]
==================
==================
artid[146370] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:52] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146354], title[]
[[1;32mSUCC    [0m 04-05 12:09:52] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146354], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:09:52] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146354], title[]
[[1;36mINFO    [0m 04-05 12:09:53] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146371]
==================
set proxy[https://120.92.118.64:10010] artid[146371]
==================
==================
artid[146371] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:53] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146355], title[谢谢大佬们的赞]
[[1;32mSUCC    [0m 04-05 12:09:53] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146355], title[谢谢大佬们的赞], table[article]
[[1;32mSUCC    [0m 04-05 12:09:53] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146355], title[谢谢大佬们的赞]
[[1;36mINFO    [0m 04-05 12:09:54] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146372]
==================
set proxy[https://120.92.118.64:10010] artid[146372]
==================
==================
artid[146372] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:54] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146356], title[EOS最新资讯]
[[1;32mSUCC    [0m 04-05 12:09:54] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146356], title[EOS最新资讯], table[article]
[[1;32mSUCC    [0m 04-05 12:09:54] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146356], title[EOS最新资讯]
[[1;36mINFO    [0m 04-05 12:09:56] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146373]
==================
set proxy[https://120.92.118.64:10010] artid[146373]
==================
==================
artid[146373] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:56] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146357], title[最好的加密货币]
[[1;32mSUCC    [0m 04-05 12:09:56] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146357], title[最好的加密货币], table[article]
[[1;32mSUCC    [0m 04-05 12:09:56] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146357], title[最好的加密货币]
[[1;36mINFO    [0m 04-05 12:09:57] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146374]
==================
set proxy[https://120.92.118.64:10010] artid[146374]
==================
==================
artid[146374] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:57] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146358], title[]
[[1;32mSUCC    [0m 04-05 12:09:57] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146358], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:09:57] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146358], title[]
[[1;36mINFO    [0m 04-05 12:09:58] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146375]
==================
set proxy[https://120.92.118.64:10010] artid[146375]
==================
==================
artid[146375] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:58] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146359], title[这一张图就能让你看懂BTC下一步会怎么走？]
[[1;32mSUCC    [0m 04-05 12:09:58] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146359], title[这一张图就能让你看懂BTC下一步会怎么走？], table[article]
[[1;32mSUCC    [0m 04-05 12:09:58] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146359], title[这一张图就能让你看懂BTC下一步会怎么走？]
[[1;36mINFO    [0m 04-05 12:09:59] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146376]
==================
set proxy[https://120.92.118.64:10010] artid[146376]
==================
==================
artid[146376] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:09:59] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146360], title[]
[[1;32mSUCC    [0m 04-05 12:09:59] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146360], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:09:59] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146360], title[]
[[1;36mINFO    [0m 04-05 12:10:00] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146377]
==================
set proxy[https://120.92.118.64:10010] artid[146377]
==================
==================
artid[146377] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:00] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146361], title[币圈故事——“泡沫”之夏（三）]
[[1;32mSUCC    [0m 04-05 12:10:00] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146361], title[币圈故事——“泡沫”之夏（三）], table[article]
[[1;32mSUCC    [0m 04-05 12:10:00] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146361], title[币圈故事——“泡沫”之夏（三）]
[[1;36mINFO    [0m 04-05 12:10:01] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146378]
==================
set proxy[https://120.92.118.64:10010] artid[146378]
==================
==================
artid[146378] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:01] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146362], title[]
[[1;32mSUCC    [0m 04-05 12:10:01] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146362], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:10:01] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146362], title[]
[[1;36mINFO    [0m 04-05 12:10:02] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146379]
==================
set proxy[https://120.92.118.64:10010] artid[146379]
==================
==================
artid[146379] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:03] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146363], title[比特币的前景和未来]
[[1;32mSUCC    [0m 04-05 12:10:03] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146363], title[比特币的前景和未来], table[article]
[[1;32mSUCC    [0m 04-05 12:10:03] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146363], title[比特币的前景和未来]
[[1;36mINFO    [0m 04-05 12:10:03] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146380]
==================
set proxy[https://120.92.118.64:10010] artid[146380]
==================
==================
artid[146380] proxy_index[3]
==================
[[1;31mERROR   [0m 04-05 12:10:03] [XZLog] [article_week_loop.py:110:parse_item] raw_str[{"data":{"boardCode":"EOS","boardId":"5","boardName":"EOS","boards":[{"boardCode":"EOS","boardId":5,"boardName":"EOS"}],"cmtList":[],"cmts":1,"content":"币乎没上市之前一直在试用，从2月28日上市一个月了，可是有些程序感觉不够好，就如充值，我问了好多人都不知道怎么充值购买，这个问题是不是能改进一下，发布一下如何去充值步骤，                     我用的是世界环保币，够买还是卖非常明确，如何挂单买多少，希望币乎在这方面也能改进💪💪💪","creatime":1522298478000,"del":false,"down":0,"downList":[],"downs":0,"follow":0,"fs":1,"id":146364,"imgList":[{"name":"img/af384a7f2a459a464421e8be2b88e3a8.jpeg","resId":"0"},{"name":"img/b7ed58626eb0fff27ba5d3338552160c.jpeg","resId":"0"}],"money":2.44,"rtf":0,"snapContent":"币乎没上市之前一直在试用，从2月28日上市一个月了，可是有些程序感觉不够好，就如充值，我问了好多人都不知道怎么充值购买，这个问题是不是能改进","title":"","up":0,"upList":[],"updatime":1522298478000,"ups":4,"userIcon":"img/641703cf7a7417095bfbed71c649b8d5.jpeg","userId":151580,"userName":"冰镇整个夏天","valid":0},"res":1,"resMsg":"success"}], EX[unacceptable character #x1f4aa: special characters are not allowed
  in "<unicode string>", position 299]
[[1;36mINFO    [0m 04-05 12:10:04] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146381]
==================
set proxy[https://120.92.118.64:10010] artid[146381]
==================
==================
artid[146381] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:04] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146365], title[]
[[1;32mSUCC    [0m 04-05 12:10:04] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146365], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:10:04] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146365], title[]
[[1;36mINFO    [0m 04-05 12:10:06] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146382]
==================
set proxy[https://120.92.118.64:10010] artid[146382]
==================
==================
artid[146382] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:06] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146366], title[金蝶集团创始人徐少春：区块链或将会消灭所有假账]
[[1;32mSUCC    [0m 04-05 12:10:06] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146366], title[金蝶集团创始人徐少春：区块链或将会消灭所有假账], table[article]
[[1;32mSUCC    [0m 04-05 12:10:06] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146366], title[金蝶集团创始人徐少春：区块链或将会消灭所有假账]
[[1;36mINFO    [0m 04-05 12:10:07] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146383]
==================
set proxy[https://120.92.118.64:10010] artid[146383]
==================
==================
artid[146383] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:07] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146367], title[]
[[1;32mSUCC    [0m 04-05 12:10:07] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146367], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:10:07] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146367], title[]
[[1;36mINFO    [0m 04-05 12:10:09] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146384]
==================
set proxy[https://120.92.118.64:10010] artid[146384]
==================
==================
artid[146384] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:09] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146368], title[笨小笑:  智能合约——让她下班再难受！]
[[1;32mSUCC    [0m 04-05 12:10:09] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146368], title[笨小笑:  智能合约——让她下班再难受！], table[article]
[[1;32mSUCC    [0m 04-05 12:10:09] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146368], title[笨小笑:  智能合约——让她下班再难受！]
[[1;36mINFO    [0m 04-05 12:10:09] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146385]
==================
set proxy[https://120.92.118.64:10010] artid[146385]
==================
==================
artid[146385] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:09] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146369], title[那些买了比特币的人，现在生活怎么样了？]
[[1;32mSUCC    [0m 04-05 12:10:09] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146369], title[那些买了比特币的人，现在生活怎么样了？], table[article]
[[1;32mSUCC    [0m 04-05 12:10:09] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146369], title[那些买了比特币的人，现在生活怎么样了？]
[[1;36mINFO    [0m 04-05 12:10:11] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146386]
==================
set proxy[https://120.92.118.64:10010] artid[146386]
==================
==================
artid[146386] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:11] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146370], title[okex到底怎么了？]
[[1;32mSUCC    [0m 04-05 12:10:11] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146370], title[okex到底怎么了？], table[article]
[[1;32mSUCC    [0m 04-05 12:10:11] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146370], title[okex到底怎么了？]
[[1;36mINFO    [0m 04-05 12:10:11] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146387]
==================
set proxy[https://120.92.118.64:10010] artid[146387]
==================
==================
artid[146387] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:12] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146371], title[]
[[1;32mSUCC    [0m 04-05 12:10:12] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146371], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:10:12] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146371], title[]
[[1;36mINFO    [0m 04-05 12:10:12] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146388]
==================
set proxy[https://120.92.118.64:10010] artid[146388]
==================
==================
artid[146388] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:12] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146372], title[【识币】如何运用第一性原理准确找到价值币种]
[[1;32mSUCC    [0m 04-05 12:10:13] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146372], title[【识币】如何运用第一性原理准确找到价值币种], table[article]
[[1;32mSUCC    [0m 04-05 12:10:13] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146372], title[【识币】如何运用第一性原理准确找到价值币种]
[[1;36mINFO    [0m 04-05 12:10:14] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146389]
==================
set proxy[https://120.92.118.64:10010] artid[146389]
==================
==================
artid[146389] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:14] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146373], title[EOS团队是真要先砸ETH再拉自己吗？]
[[1;32mSUCC    [0m 04-05 12:10:14] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146373], title[EOS团队是真要先砸ETH再拉自己吗？], table[article]
[[1;32mSUCC    [0m 04-05 12:10:14] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146373], title[EOS团队是真要先砸ETH再拉自己吗？]
[[1;36mINFO    [0m 04-05 12:10:15] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146390]
==================
set proxy[https://120.92.118.64:10010] artid[146390]
==================
==================
artid[146390] proxy_index[3]
==================
[[1;31mERROR   [0m 04-05 12:10:15] [XZLog] [article_week_loop.py:110:parse_item] raw_str[{"data":{"boardCode":"KEY","boardId":"7","boardName":"KEY","boards":[{"boardCode":"KEY","boardId":7,"boardName":"KEY"}],"cmtList":[],"cmts":1,"content":"币乎没上市之前一直在试用，从2月28日上市一个月了，可是有些程序感觉不够好，就如充值，我问了好多人都不知道怎么充值购买，这个问题是不是能改进一下，发布一下如何去充值步骤，                     我用的是世界环保币，够买还是卖非常明确，如何挂单买多少，希望币乎在这方面也能改进💪💪💪","creatime":1522298763000,"del":false,"down":0,"downList":[],"downs":0,"follow":0,"fs":1,"id":146374,"imgList":[{"name":"img/c7064642f5a1ebc2f0a4487b0a2f4bda.jpeg","resId":"0"},{"name":"img/b74605f15420c65a797a899d124ca451.jpeg","resId":"0"}],"money":0.99,"rtf":0,"snapContent":"币乎没上市之前一直在试用，从2月28日上市一个月了，可是有些程序感觉不够好，就如充值，我问了好多人都不知道怎么充值购买，这个问题是不是能改进","title":"币乎如何购买充值","up":0,"upList":[],"updatime":1522298763000,"ups":3,"userIcon":"img/641703cf7a7417095bfbed71c649b8d5.jpeg","userId":151580,"userName":"冰镇整个夏天","valid":0},"res":1,"resMsg":"success"}], EX[unacceptable character #x1f4aa: special characters are not allowed
  in "<unicode string>", position 299]
[[1;36mINFO    [0m 04-05 12:10:16] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146391]
==================
set proxy[https://120.92.118.64:10010] artid[146391]
==================
==================
artid[146391] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:17] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146375], title[币乎不能添加图片或是截图吗？]
[[1;32mSUCC    [0m 04-05 12:10:17] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146375], title[币乎不能添加图片或是截图吗？], table[article]
[[1;32mSUCC    [0m 04-05 12:10:17] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146375], title[币乎不能添加图片或是截图吗？]
[[1;36mINFO    [0m 04-05 12:10:18] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146392]
==================
set proxy[https://120.92.118.64:10010] artid[146392]
==================
==================
artid[146392] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:18] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146376], title[]
[[1;32mSUCC    [0m 04-05 12:10:18] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146376], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:10:18] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146376], title[]
[[1;36mINFO    [0m 04-05 12:10:19] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146393]
==================
set proxy[https://120.92.118.64:10010] artid[146393]
==================
==================
artid[146393] proxy_index[3]
==================
[[1;31mERROR   [0m 04-05 12:10:19] [XZLog] [article_week_loop.py:110:parse_item] raw_str[{"data":{"boardCode":"EOS","boardId":"5","boardName":"EOS","boards":[{"boardCode":"EOS","boardId":5,"boardName":"EOS"}],"cmtList":[],"cmts":3,"content":"币乎没上市之前一直在试用，从2月28日上市一个月了，可是有些程序感觉不够好，就如充值，我问了好多人都不知道怎么充值购买，这个问题是不是能改进一下，发布一下如何去充值步骤，                     我用的是世界环保币，够买还是卖非常明确，如何挂单买多少，希望币乎在这方面也能改进💪💪💪","creatime":1522298808000,"del":false,"down":0,"downList":[],"downs":0,"follow":0,"fs":1,"id":146377,"imgList":[{"name":"img/39089fb9689d07f583b306e26444caf6.jpeg","resId":"0"},{"name":"img/edae02df285214b71e9c36873a18162f.jpeg","resId":"0"}],"money":6.21,"rtf":0,"snapContent":"币乎没上市之前一直在试用，从2月28日上市一个月了，可是有些程序感觉不够好，就如充值，我问了好多人都不知道怎么充值购买，这个问题是不是能改进","title":"","up":0,"upList":[],"updatime":1522298808000,"ups":10,"userIcon":"img/641703cf7a7417095bfbed71c649b8d5.jpeg","userId":151580,"userName":"冰镇整个夏天","valid":0},"res":1,"resMsg":"success"}], EX[unacceptable character #x1f4aa: special characters are not allowed
  in "<unicode string>", position 299]
[[1;36mINFO    [0m 04-05 12:10:20] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146394]
==================
set proxy[https://120.92.118.64:10010] artid[146394]
==================
==================
artid[146394] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:20] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146378], title[]
[[1;32mSUCC    [0m 04-05 12:10:20] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146378], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:10:20] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146378], title[]
[[1;36mINFO    [0m 04-05 12:10:21] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146395]
==================
set proxy[https://120.92.118.64:10010] artid[146395]
==================
==================
artid[146395] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:21] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146379], title[EOS的5万户侯]
[[1;32mSUCC    [0m 04-05 12:10:21] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146379], title[EOS的5万户侯], table[article]
[[1;32mSUCC    [0m 04-05 12:10:21] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146379], title[EOS的5万户侯]
[[1;36mINFO    [0m 04-05 12:10:22] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146396]
==================
set proxy[https://120.92.118.64:10010] artid[146396]
==================
==================
artid[146396] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:22] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146380], title[比特币支持商再下一城]
[[1;32mSUCC    [0m 04-05 12:10:22] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146380], title[比特币支持商再下一城], table[article]
[[1;32mSUCC    [0m 04-05 12:10:22] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146380], title[比特币支持商再下一城]
[[1;36mINFO    [0m 04-05 12:10:24] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146397]
==================
set proxy[https://120.92.118.64:10010] artid[146397]
==================
==================
artid[146397] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:24] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146381], title[【币乎会把更多的币友赶向爬虫吗？】机器人问题，能解决吗？88元的爬虫，一天回本？三天回本？能下决定封杀爬虫ID吗？]
[[1;32mSUCC    [0m 04-05 12:10:24] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146381], title[【币乎会把更多的币友赶向爬虫吗？】机器人问题，能解决吗？88元的爬虫，一天回本？三天回本？能下决定封杀爬虫ID吗？], table[article]
[[1;32mSUCC    [0m 04-05 12:10:24] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146381], title[【币乎会把更多的币友赶向爬虫吗？】机器人问题，能解决吗？88元的爬虫，一天回本？三天回本？能下决定封杀爬虫ID吗？]
[[1;36mINFO    [0m 04-05 12:10:25] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146398]
==================
set proxy[https://120.92.118.64:10010] artid[146398]
==================
==================
artid[146398] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:25] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146382], title[今年是独角兽年]
[[1;32mSUCC    [0m 04-05 12:10:25] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146382], title[今年是独角兽年], table[article]
[[1;32mSUCC    [0m 04-05 12:10:25] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146382], title[今年是独角兽年]
[[1;36mINFO    [0m 04-05 12:10:26] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146399]
==================
set proxy[https://120.92.118.64:10010] artid[146399]
==================
==================
artid[146399] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:26] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146383], title[跌到怀疑人生]
[[1;32mSUCC    [0m 04-05 12:10:26] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146383], title[跌到怀疑人生], table[article]
[[1;32mSUCC    [0m 04-05 12:10:26] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146383], title[跌到怀疑人生]
[[1;36mINFO    [0m 04-05 12:10:27] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146400]
==================
set proxy[https://120.92.118.64:10010] artid[146400]
==================
==================
artid[146400] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:27] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146384], title[今日行情]
[[1;32mSUCC    [0m 04-05 12:10:27] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146384], title[今日行情], table[article]
[[1;32mSUCC    [0m 04-05 12:10:27] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146384], title[今日行情]
[[1;36mINFO    [0m 04-05 12:10:29] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146401]
==================
set proxy[https://120.92.118.64:10010] artid[146401]
==================
==================
artid[146401] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:29] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146385], title[]
[[1;32mSUCC    [0m 04-05 12:10:29] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146385], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:10:29] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146385], title[]
[[1;36mINFO    [0m 04-05 12:10:30] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146402]
==================
set proxy[https://120.92.118.64:10010] artid[146402]
==================
==================
artid[146402] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:31] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146386], title[ 币乎能量赞的一个小细节，你注意到了吗？]
[[1;32mSUCC    [0m 04-05 12:10:31] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146386], title[ 币乎能量赞的一个小细节，你注意到了吗？], table[article]
[[1;32mSUCC    [0m 04-05 12:10:31] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146386], title[ 币乎能量赞的一个小细节，你注意到了吗？]
[[1;36mINFO    [0m 04-05 12:10:32] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146403]
==================
set proxy[https://120.92.118.64:10010] artid[146403]
==================
==================
artid[146403] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:32] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146387], title[【中国银行:对数字货币监管提出三点建议】]
[[1;32mSUCC    [0m 04-05 12:10:32] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146387], title[【中国银行:对数字货币监管提出三点建议】], table[article]
[[1;32mSUCC    [0m 04-05 12:10:32] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146387], title[【中国银行:对数字货币监管提出三点建议】]
[[1;36mINFO    [0m 04-05 12:10:32] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146404]
==================
set proxy[https://120.92.118.64:10010] artid[146404]
==================
==================
artid[146404] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:33] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146388], title[为什么比特大陆的ASIC永远不会取代GPU矿机]
[[1;32mSUCC    [0m 04-05 12:10:33] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146388], title[为什么比特大陆的ASIC永远不会取代GPU矿机], table[article]
[[1;32mSUCC    [0m 04-05 12:10:33] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146388], title[为什么比特大陆的ASIC永远不会取代GPU矿机]
[[1;36mINFO    [0m 04-05 12:10:34] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146405]
==================
set proxy[https://120.92.118.64:10010] artid[146405]
==================
==================
artid[146405] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:34] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146389], title[Bitfinex正在考虑向迁移至瑞士]
[[1;32mSUCC    [0m 04-05 12:10:34] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146389], title[Bitfinex正在考虑向迁移至瑞士], table[article]
[[1;32mSUCC    [0m 04-05 12:10:34] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146389], title[Bitfinex正在考虑向迁移至瑞士]
[[1;36mINFO    [0m 04-05 12:10:35] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146406]
==================
set proxy[https://120.92.118.64:10010] artid[146406]
==================
==================
artid[146406] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:35] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146390], title[英雄链涉嫌诈骗已被公安立案]
[[1;32mSUCC    [0m 04-05 12:10:35] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146390], title[英雄链涉嫌诈骗已被公安立案], table[article]
[[1;32mSUCC    [0m 04-05 12:10:35] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146390], title[英雄链涉嫌诈骗已被公安立案]
[[1;36mINFO    [0m 04-05 12:10:36] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146407]
==================
set proxy[https://120.92.118.64:10010] artid[146407]
==================
==================
artid[146407] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:36] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146391], title[投资币市可以一夜暴富吗？]
[[1;32mSUCC    [0m 04-05 12:10:36] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146391], title[投资币市可以一夜暴富吗？], table[article]
[[1;32mSUCC    [0m 04-05 12:10:36] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146391], title[投资币市可以一夜暴富吗？]
[[1;36mINFO    [0m 04-05 12:10:37] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146408]
==================
set proxy[https://120.92.118.64:10010] artid[146408]
==================
==================
artid[146408] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:37] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146392], title[【又来利好】白俄罗斯正式合法化加密货币，挖矿和交易统统免税]
[[1;32mSUCC    [0m 04-05 12:10:37] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146392], title[【又来利好】白俄罗斯正式合法化加密货币，挖矿和交易统统免税], table[article]
[[1;32mSUCC    [0m 04-05 12:10:37] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146392], title[【又来利好】白俄罗斯正式合法化加密货币，挖矿和交易统统免税]
[[1;36mINFO    [0m 04-05 12:10:38] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146409]
==================
set proxy[https://120.92.118.64:10010] artid[146409]
==================
==================
artid[146409] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:38] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146393], title[最后最后一跌，黎明前的黑暗]
[[1;32mSUCC    [0m 04-05 12:10:38] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146393], title[最后最后一跌，黎明前的黑暗], table[article]
[[1;32mSUCC    [0m 04-05 12:10:38] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146393], title[最后最后一跌，黎明前的黑暗]
[[1;36mINFO    [0m 04-05 12:10:39] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146410]
==================
set proxy[https://120.92.118.64:10010] artid[146410]
==================
==================
artid[146410] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:40] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146394], title[比特币大跌了]
[[1;32mSUCC    [0m 04-05 12:10:40] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146394], title[比特币大跌了], table[article]
[[1;32mSUCC    [0m 04-05 12:10:40] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146394], title[比特币大跌了]
[[1;36mINFO    [0m 04-05 12:10:41] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146411]
==================
set proxy[https://120.92.118.64:10010] artid[146411]
==================
==================
artid[146411] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:41] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146395], title[看各家之言，给大家推荐的区块链中文网站]
[[1;32mSUCC    [0m 04-05 12:10:41] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146395], title[看各家之言，给大家推荐的区块链中文网站], table[article]
[[1;32mSUCC    [0m 04-05 12:10:41] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146395], title[看各家之言，给大家推荐的区块链中文网站]
[[1;36mINFO    [0m 04-05 12:10:42] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146412]
==================
set proxy[https://120.92.118.64:10010] artid[146412]
==================
==================
artid[146412] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:42] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146396], title[]
[[1;32mSUCC    [0m 04-05 12:10:42] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146396], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:10:42] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146396], title[]
[[1;36mINFO    [0m 04-05 12:10:43] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146413]
==================
set proxy[https://120.92.118.64:10010] artid[146413]
==================
==================
artid[146413] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:43] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146397], title[比特小故事（11）之奥萨大平原之战-上]
[[1;32mSUCC    [0m 04-05 12:10:43] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146397], title[比特小故事（11）之奥萨大平原之战-上], table[article]
[[1;32mSUCC    [0m 04-05 12:10:43] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146397], title[比特小故事（11）之奥萨大平原之战-上]
[[1;36mINFO    [0m 04-05 12:10:44] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146414]
==================
set proxy[https://120.92.118.64:10010] artid[146414]
==================
==================
artid[146414] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:44] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146398], title[第二届全球金融科技与区块链峰会开幕在即，臻金应邀参与]
[[1;32mSUCC    [0m 04-05 12:10:44] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146398], title[第二届全球金融科技与区块链峰会开幕在即，臻金应邀参与], table[article]
[[1;32mSUCC    [0m 04-05 12:10:44] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146398], title[第二届全球金融科技与区块链峰会开幕在即，臻金应邀参与]
[[1;36mINFO    [0m 04-05 12:10:45] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146415]
==================
set proxy[https://120.92.118.64:10010] artid[146415]
==================
==================
artid[146415] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:45] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146399], title[]
[[1;32mSUCC    [0m 04-05 12:10:45] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146399], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:10:45] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146399], title[]
[[1;36mINFO    [0m 04-05 12:10:46] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146416]
==================
set proxy[https://120.92.118.64:10010] artid[146416]
==================
==================
artid[146416] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:46] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146400], title[币圈故事——“泡沫”之夏（四）]
[[1;32mSUCC    [0m 04-05 12:10:46] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146400], title[币圈故事——“泡沫”之夏（四）], table[article]
[[1;32mSUCC    [0m 04-05 12:10:46] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146400], title[币圈故事——“泡沫”之夏（四）]
[[1;36mINFO    [0m 04-05 12:10:47] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146417]
==================
set proxy[https://120.92.118.64:10010] artid[146417]
==================
==================
artid[146417] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:47] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146401], title[]
[[1;32mSUCC    [0m 04-05 12:10:47] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146401], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:10:47] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146401], title[]
[[1;36mINFO    [0m 04-05 12:10:48] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146418]
==================
set proxy[https://120.92.118.64:10010] artid[146418]
==================
==================
artid[146418] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:48] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146402], title[]
[[1;32mSUCC    [0m 04-05 12:10:48] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146402], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:10:48] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146402], title[]
[[1;36mINFO    [0m 04-05 12:10:50] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146419]
==================
set proxy[https://120.92.118.64:10010] artid[146419]
==================
==================
artid[146419] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:50] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146403], title[]
[[1;32mSUCC    [0m 04-05 12:10:50] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146403], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:10:50] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146403], title[]
[[1;36mINFO    [0m 04-05 12:10:51] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146420]
==================
set proxy[https://120.92.118.64:10010] artid[146420]
==================
==================
artid[146420] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:51] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146404], title[从今日起，全心全意做一个区块链分享者]
[[1;32mSUCC    [0m 04-05 12:10:51] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146404], title[从今日起，全心全意做一个区块链分享者], table[article]
[[1;32mSUCC    [0m 04-05 12:10:51] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146404], title[从今日起，全心全意做一个区块链分享者]
[[1;36mINFO    [0m 04-05 12:10:53] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146421]
==================
set proxy[https://120.92.118.64:10010] artid[146421]
==================
==================
artid[146421] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:53] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146405], title[]
[[1;32mSUCC    [0m 04-05 12:10:53] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146405], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:10:53] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146405], title[]
[[1;36mINFO    [0m 04-05 12:10:54] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146422]
==================
set proxy[https://120.92.118.64:10010] artid[146422]
==================
==================
artid[146422] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:54] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146406], title[]
[[1;32mSUCC    [0m 04-05 12:10:54] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146406], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:10:54] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146406], title[]
[[1;36mINFO    [0m 04-05 12:10:55] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146423]
==================
set proxy[https://120.92.118.64:10010] artid[146423]
==================
==================
artid[146423] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:55] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146407], title[]
[[1;32mSUCC    [0m 04-05 12:10:55] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146407], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:10:55] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146407], title[]
[[1;36mINFO    [0m 04-05 12:10:56] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146424]
==================
set proxy[https://120.92.118.64:10010] artid[146424]
==================
==================
artid[146424] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:56] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146408], title[]
[[1;32mSUCC    [0m 04-05 12:10:56] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146408], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:10:56] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146408], title[]
[[1;36mINFO    [0m 04-05 12:10:57] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146425]
==================
set proxy[https://120.92.118.64:10010] artid[146425]
==================
==================
artid[146425] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:58] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146409], title[区块链一夜爆红，上演抢人大战！快播王欣微博发声，或将入局…… ]
[[1;32mSUCC    [0m 04-05 12:10:58] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146409], title[区块链一夜爆红，上演抢人大战！快播王欣微博发声，或将入局…… ], table[article]
[[1;32mSUCC    [0m 04-05 12:10:58] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146409], title[区块链一夜爆红，上演抢人大战！快播王欣微博发声，或将入局…… ]
[[1;36mINFO    [0m 04-05 12:10:58] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146426]
==================
set proxy[https://120.92.118.64:10010] artid[146426]
==================
==================
artid[146426] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:10:59] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146410], title[韩国：将有6000多家商店提供加密货币支付选择]
[[1;32mSUCC    [0m 04-05 12:10:59] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146410], title[韩国：将有6000多家商店提供加密货币支付选择], table[article]
[[1;32mSUCC    [0m 04-05 12:10:59] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146410], title[韩国：将有6000多家商店提供加密货币支付选择]
[[1;36mINFO    [0m 04-05 12:11:00] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146427]
==================
set proxy[https://120.92.118.64:10010] artid[146427]
==================
==================
artid[146427] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:00] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146411], title[每日区块链财经（2018年3月29日）]
[[1;32mSUCC    [0m 04-05 12:11:00] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146411], title[每日区块链财经（2018年3月29日）], table[article]
[[1;32mSUCC    [0m 04-05 12:11:00] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146411], title[每日区块链财经（2018年3月29日）]
[[1;36mINFO    [0m 04-05 12:11:01] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146428]
==================
set proxy[https://120.92.118.64:10010] artid[146428]
==================
==================
artid[146428] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:01] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146412], title[区块链三大毒瘤ICO项目，割韭菜套路令人大跌眼镜]
[[1;32mSUCC    [0m 04-05 12:11:01] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146412], title[区块链三大毒瘤ICO项目，割韭菜套路令人大跌眼镜], table[article]
[[1;32mSUCC    [0m 04-05 12:11:01] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146412], title[区块链三大毒瘤ICO项目，割韭菜套路令人大跌眼镜]
[[1;36mINFO    [0m 04-05 12:11:02] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146429]
==================
set proxy[https://120.92.118.64:10010] artid[146429]
==================
==================
artid[146429] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:02] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146413], title[]
[[1;32mSUCC    [0m 04-05 12:11:02] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146413], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:11:02] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146413], title[]
[[1;36mINFO    [0m 04-05 12:11:03] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146430]
==================
set proxy[https://120.92.118.64:10010] artid[146430]
==================
==================
artid[146430] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:03] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146414], title[]
[[1;32mSUCC    [0m 04-05 12:11:03] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146414], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:11:03] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146414], title[]
[[1;36mINFO    [0m 04-05 12:11:04] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146431]
==================
set proxy[https://120.92.118.64:10010] artid[146431]
==================
==================
artid[146431] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:04] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146415], title[我为什么坚定看好币乎？]
[[1;32mSUCC    [0m 04-05 12:11:04] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146415], title[我为什么坚定看好币乎？], table[article]
[[1;32mSUCC    [0m 04-05 12:11:04] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146415], title[我为什么坚定看好币乎？]
[[1;36mINFO    [0m 04-05 12:11:05] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146432]
==================
set proxy[https://120.92.118.64:10010] artid[146432]
==================
==================
artid[146432] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:05] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146416], title[JEX]
[[1;32mSUCC    [0m 04-05 12:11:05] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146416], title[JEX], table[article]
[[1;32mSUCC    [0m 04-05 12:11:05] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146416], title[JEX]
[[1;36mINFO    [0m 04-05 12:11:06] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146433]
==================
set proxy[https://120.92.118.64:10010] artid[146433]
==================
==================
artid[146433] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:06] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146417], title[]
[[1;32mSUCC    [0m 04-05 12:11:06] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146417], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:11:06] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146417], title[]
[[1;36mINFO    [0m 04-05 12:11:07] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146434]
==================
set proxy[https://120.92.118.64:10010] artid[146434]
==================
==================
artid[146434] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:07] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146418], title[英雄链欺诈罪已经立案]
[[1;32mSUCC    [0m 04-05 12:11:08] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146418], title[英雄链欺诈罪已经立案], table[article]
[[1;32mSUCC    [0m 04-05 12:11:08] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146418], title[英雄链欺诈罪已经立案]
[[1;36mINFO    [0m 04-05 12:11:08] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146435]
==================
set proxy[https://120.92.118.64:10010] artid[146435]
==================
==================
artid[146435] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:08] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146419], title[币圈又惊爆传销币，涉案金额过亿，匿名人士爆料称涉案人员乃惯犯]
[[1;32mSUCC    [0m 04-05 12:11:08] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146419], title[币圈又惊爆传销币，涉案金额过亿，匿名人士爆料称涉案人员乃惯犯], table[article]
[[1;32mSUCC    [0m 04-05 12:11:08] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146419], title[币圈又惊爆传销币，涉案金额过亿，匿名人士爆料称涉案人员乃惯犯]
[[1;36mINFO    [0m 04-05 12:11:09] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146436]
==================
set proxy[https://120.92.118.64:10010] artid[146436]
==================
==================
artid[146436] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:09] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146420], title[算力]
[[1;32mSUCC    [0m 04-05 12:11:09] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146420], title[算力], table[article]
[[1;32mSUCC    [0m 04-05 12:11:09] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146420], title[算力]
[[1;36mINFO    [0m 04-05 12:11:10] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146437]
==================
set proxy[https://120.92.118.64:10010] artid[146437]
==================
==================
artid[146437] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:10] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146421], title[锐角机一台能上网，能挖矿的神机]
[[1;32mSUCC    [0m 04-05 12:11:10] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146421], title[锐角机一台能上网，能挖矿的神机], table[article]
[[1;32mSUCC    [0m 04-05 12:11:10] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146421], title[锐角机一台能上网，能挖矿的神机]
[[1;36mINFO    [0m 04-05 12:11:11] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146438]
==================
set proxy[https://120.92.118.64:10010] artid[146438]
==================
==================
artid[146438] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:11] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146422], title[算力]
[[1;32mSUCC    [0m 04-05 12:11:11] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146422], title[算力], table[article]
[[1;32mSUCC    [0m 04-05 12:11:11] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146422], title[算力]
[[1;36mINFO    [0m 04-05 12:11:12] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146439]
==================
set proxy[https://120.92.118.64:10010] artid[146439]
==================
==================
artid[146439] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:13] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146423], title[pow]
[[1;32mSUCC    [0m 04-05 12:11:13] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146423], title[pow], table[article]
[[1;32mSUCC    [0m 04-05 12:11:13] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146423], title[pow]
[[1;36mINFO    [0m 04-05 12:11:13] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146440]
==================
set proxy[https://120.92.118.64:10010] artid[146440]
==================
==================
artid[146440] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:14] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146424], title[【蓝狐笔记】墨客：让DApp落地的公链]
[[1;32mSUCC    [0m 04-05 12:11:14] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146424], title[【蓝狐笔记】墨客：让DApp落地的公链], table[article]
[[1;32mSUCC    [0m 04-05 12:11:14] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146424], title[【蓝狐笔记】墨客：让DApp落地的公链]
[[1;36mINFO    [0m 04-05 12:11:15] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146441]
==================
set proxy[https://120.92.118.64:10010] artid[146441]
==================
==================
artid[146441] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:15] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146425], title[ 区块链这么火，再不行动会不会错过几个亿？]
[[1;32mSUCC    [0m 04-05 12:11:15] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146425], title[ 区块链这么火，再不行动会不会错过几个亿？], table[article]
[[1;32mSUCC    [0m 04-05 12:11:15] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146425], title[ 区块链这么火，再不行动会不会错过几个亿？]
[[1;36mINFO    [0m 04-05 12:11:15] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146442]
==================
set proxy[https://120.92.118.64:10010] artid[146442]
==================
==================
artid[146442] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:16] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146426], title[诗和远方]
[[1;32mSUCC    [0m 04-05 12:11:16] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146426], title[诗和远方], table[article]
[[1;32mSUCC    [0m 04-05 12:11:16] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146426], title[诗和远方]
[[1;36mINFO    [0m 04-05 12:11:17] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146443]
==================
set proxy[https://120.92.118.64:10010] artid[146443]
==================
==================
artid[146443] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:17] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146427], title[分叉币技术解析上部（5）：BP141隔离见证技术问题]
[[1;32mSUCC    [0m 04-05 12:11:17] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146427], title[分叉币技术解析上部（5）：BP141隔离见证技术问题], table[article]
[[1;32mSUCC    [0m 04-05 12:11:17] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146427], title[分叉币技术解析上部（5）：BP141隔离见证技术问题]
[[1;36mINFO    [0m 04-05 12:11:18] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146444]
==================
set proxy[https://120.92.118.64:10010] artid[146444]
==================
==================
artid[146444] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:18] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146428], title[区域链]
[[1;32mSUCC    [0m 04-05 12:11:18] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146428], title[区域链], table[article]
[[1;32mSUCC    [0m 04-05 12:11:18] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146428], title[区域链]
[[1;36mINFO    [0m 04-05 12:11:19] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146445]
==================
set proxy[https://120.92.118.64:10010] artid[146445]
==================
==================
artid[146445] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:20] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146429], title[区块链“爆款”应用离我们有多远？]
[[1;32mSUCC    [0m 04-05 12:11:20] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146429], title[区块链“爆款”应用离我们有多远？], table[article]
[[1;32mSUCC    [0m 04-05 12:11:20] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146429], title[区块链“爆款”应用离我们有多远？]
[[1;36mINFO    [0m 04-05 12:11:21] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146446]
==================
set proxy[https://120.92.118.64:10010] artid[146446]
==================
==================
artid[146446] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:21] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146430], title[]
[[1;32mSUCC    [0m 04-05 12:11:21] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146430], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:11:21] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146430], title[]
[[1;36mINFO    [0m 04-05 12:11:22] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146447]
==================
set proxy[https://120.92.118.64:10010] artid[146447]
==================
==================
artid[146447] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:22] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146431], title[]
[[1;32mSUCC    [0m 04-05 12:11:22] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146431], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:11:22] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146431], title[]
[[1;36mINFO    [0m 04-05 12:11:23] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146448]
==================
set proxy[https://120.92.118.64:10010] artid[146448]
==================
==================
artid[146448] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:23] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146432], title[分享一下我对币圈的看法。]
[[1;32mSUCC    [0m 04-05 12:11:23] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146432], title[分享一下我对币圈的看法。], table[article]
[[1;32mSUCC    [0m 04-05 12:11:23] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146432], title[分享一下我对币圈的看法。]
[[1;36mINFO    [0m 04-05 12:11:25] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146449]
==================
set proxy[https://120.92.118.64:10010] artid[146449]
==================
==================
artid[146449] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:25] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146433], title[每日币情。反弹受阻，震荡下跌。]
[[1;32mSUCC    [0m 04-05 12:11:25] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146433], title[每日币情。反弹受阻，震荡下跌。], table[article]
[[1;32mSUCC    [0m 04-05 12:11:25] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146433], title[每日币情。反弹受阻，震荡下跌。]
[[1;36mINFO    [0m 04-05 12:11:26] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146450]
==================
set proxy[https://120.92.118.64:10010] artid[146450]
==================
==================
artid[146450] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:26] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146434], title[]
[[1;32mSUCC    [0m 04-05 12:11:26] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146434], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:11:26] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146434], title[]
[[1;36mINFO    [0m 04-05 12:11:27] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146451]
==================
set proxy[https://120.92.118.64:10010] artid[146451]
==================
==================
artid[146451] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:27] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146435], title[nxt币]
[[1;32mSUCC    [0m 04-05 12:11:27] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146435], title[nxt币], table[article]
[[1;32mSUCC    [0m 04-05 12:11:27] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146435], title[nxt币]
[[1;36mINFO    [0m 04-05 12:11:29] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146452]
==================
set proxy[https://120.92.118.64:10010] artid[146452]
==================
==================
artid[146452] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:29] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146436], title[混淆]
[[1;32mSUCC    [0m 04-05 12:11:29] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146436], title[混淆], table[article]
[[1;32mSUCC    [0m 04-05 12:11:29] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146436], title[混淆]
[[1;36mINFO    [0m 04-05 12:11:30] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146453]
==================
set proxy[https://120.92.118.64:10010] artid[146453]
==================
==================
artid[146453] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:30] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146437], title[众多小白的疑问！]
[[1;32mSUCC    [0m 04-05 12:11:30] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146437], title[众多小白的疑问！], table[article]
[[1;32mSUCC    [0m 04-05 12:11:30] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146437], title[众多小白的疑问！]
[[1;36mINFO    [0m 04-05 12:11:31] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146454]
==================
set proxy[https://120.92.118.64:10010] artid[146454]
==================
==================
artid[146454] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:31] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146438], title[]
[[1;32mSUCC    [0m 04-05 12:11:31] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146438], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:11:31] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146438], title[]
[[1;36mINFO    [0m 04-05 12:11:32] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146455]
==================
set proxy[https://120.92.118.64:10010] artid[146455]
==================
==================
artid[146455] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:33] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146439], title[淘宝系，距离创世开启不到两小时了。]
[[1;32mSUCC    [0m 04-05 12:11:33] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146439], title[淘宝系，距离创世开启不到两小时了。], table[article]
[[1;32mSUCC    [0m 04-05 12:11:33] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146439], title[淘宝系，距离创世开启不到两小时了。]
[[1;36mINFO    [0m 04-05 12:11:34] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146456]
==================
set proxy[https://120.92.118.64:10010] artid[146456]
==================
==================
artid[146456] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:34] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146440], title[nxt社区]
[[1;32mSUCC    [0m 04-05 12:11:34] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146440], title[nxt社区], table[article]
[[1;32mSUCC    [0m 04-05 12:11:34] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146440], title[nxt社区]
[[1;36mINFO    [0m 04-05 12:11:35] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146457]
==================
set proxy[https://120.92.118.64:10010] artid[146457]
==================
==================
artid[146457] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:35] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146441], title[nxt领导去中心化]
[[1;32mSUCC    [0m 04-05 12:11:35] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146441], title[nxt领导去中心化], table[article]
[[1;32mSUCC    [0m 04-05 12:11:35] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146441], title[nxt领导去中心化]
[[1;36mINFO    [0m 04-05 12:11:36] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146458]
==================
set proxy[https://120.92.118.64:10010] artid[146458]
==================
==================
artid[146458] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:36] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146442], title[淘宝系，距离创世开启不到两小时了。]
[[1;32mSUCC    [0m 04-05 12:11:36] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146442], title[淘宝系，距离创世开启不到两小时了。], table[article]
[[1;32mSUCC    [0m 04-05 12:11:36] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146442], title[淘宝系，距离创世开启不到两小时了。]
[[1;36mINFO    [0m 04-05 12:11:37] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146459]
==================
set proxy[https://120.92.118.64:10010] artid[146459]
==================
==================
artid[146459] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:37] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146443], title[阿里巴巴出行通证了]
[[1;32mSUCC    [0m 04-05 12:11:37] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146443], title[阿里巴巴出行通证了], table[article]
[[1;32mSUCC    [0m 04-05 12:11:37] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146443], title[阿里巴巴出行通证了]
[[1;36mINFO    [0m 04-05 12:11:38] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146460]
==================
set proxy[https://120.92.118.64:10010] artid[146460]
==================
==================
artid[146460] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:38] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146444], title[nxt基金]
[[1;32mSUCC    [0m 04-05 12:11:38] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146444], title[nxt基金], table[article]
[[1;32mSUCC    [0m 04-05 12:11:38] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146444], title[nxt基金]
[[1;36mINFO    [0m 04-05 12:11:39] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146461]
==================
set proxy[https://120.92.118.64:10010] artid[146461]
==================
==================
artid[146461] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:39] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146445], title[nxt的过去未来]
[[1;32mSUCC    [0m 04-05 12:11:39] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146445], title[nxt的过去未来], table[article]
[[1;32mSUCC    [0m 04-05 12:11:39] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146445], title[nxt的过去未来]
[[1;36mINFO    [0m 04-05 12:11:40] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146462]
==================
set proxy[https://120.92.118.64:10010] artid[146462]
==================
==================
artid[146462] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:41] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146446], title[]
[[1;32mSUCC    [0m 04-05 12:11:41] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146446], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:11:41] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146446], title[]
[[1;36mINFO    [0m 04-05 12:11:42] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146463]
==================
set proxy[https://120.92.118.64:10010] artid[146463]
==================
==================
artid[146463] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:42] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146447], title[]
[[1;32mSUCC    [0m 04-05 12:11:42] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146447], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:11:42] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146447], title[]
[[1;36mINFO    [0m 04-05 12:11:43] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146464]
==================
set proxy[https://120.92.118.64:10010] artid[146464]
==================
==================
artid[146464] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:43] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146448], title[熊市与牛市哪个期间买进最佳]
[[1;32mSUCC    [0m 04-05 12:11:43] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146448], title[熊市与牛市哪个期间买进最佳], table[article]
[[1;32mSUCC    [0m 04-05 12:11:43] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146448], title[熊市与牛市哪个期间买进最佳]
[[1;36mINFO    [0m 04-05 12:11:44] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146465]
==================
set proxy[https://120.92.118.64:10010] artid[146465]
==================
==================
artid[146465] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:44] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146449], title[早投入比特币的人，现在生活咋样]
[[1;32mSUCC    [0m 04-05 12:11:44] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146449], title[早投入比特币的人，现在生活咋样], table[article]
[[1;32mSUCC    [0m 04-05 12:11:44] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146449], title[早投入比特币的人，现在生活咋样]
[[1;36mINFO    [0m 04-05 12:11:45] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146466]
==================
set proxy[https://120.92.118.64:10010] artid[146466]
==================
==================
artid[146466] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:45] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146450], title[熊市炒币绝学篇————超低埋伏篇]
[[1;32mSUCC    [0m 04-05 12:11:45] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146450], title[熊市炒币绝学篇————超低埋伏篇], table[article]
[[1;32mSUCC    [0m 04-05 12:11:45] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146450], title[熊市炒币绝学篇————超低埋伏篇]
[[1;36mINFO    [0m 04-05 12:11:46] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146467]
==================
set proxy[https://120.92.118.64:10010] artid[146467]
==================
==================
artid[146467] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:46] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146451], title[惊天风险！币安、OKCoin等众多交易所被曝存在严重安全漏洞]
[[1;32mSUCC    [0m 04-05 12:11:46] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146451], title[惊天风险！币安、OKCoin等众多交易所被曝存在严重安全漏洞], table[article]
[[1;32mSUCC    [0m 04-05 12:11:46] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146451], title[惊天风险！币安、OKCoin等众多交易所被曝存在严重安全漏洞]
[[1;36mINFO    [0m 04-05 12:11:47] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146468]
==================
set proxy[https://120.92.118.64:10010] artid[146468]
==================
==================
artid[146468] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:47] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146452], title[最近又是一直瀑布]
[[1;32mSUCC    [0m 04-05 12:11:47] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146452], title[最近又是一直瀑布], table[article]
[[1;32mSUCC    [0m 04-05 12:11:47] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146452], title[最近又是一直瀑布]
[[1;36mINFO    [0m 04-05 12:11:48] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146469]
==================
set proxy[https://120.92.118.64:10010] artid[146469]
==================
==================
artid[146469] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:48] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146453], title[BTC破8000$]
[[1;32mSUCC    [0m 04-05 12:11:48] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146453], title[BTC破8000$], table[article]
[[1;32mSUCC    [0m 04-05 12:11:48] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146453], title[BTC破8000$]
[[1;36mINFO    [0m 04-05 12:11:49] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146470]
==================
set proxy[https://120.92.118.64:10010] artid[146470]
==================
==================
artid[146470] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:50] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146454], title[]
[[1;32mSUCC    [0m 04-05 12:11:50] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146454], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:11:50] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146454], title[]
[[1;36mINFO    [0m 04-05 12:11:51] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146471]
==================
set proxy[https://120.92.118.64:10010] artid[146471]
==================
==================
artid[146471] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:51] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146455], title[]
[[1;32mSUCC    [0m 04-05 12:11:51] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146455], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:11:51] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146455], title[]
[[1;36mINFO    [0m 04-05 12:11:52] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146472]
==================
set proxy[https://120.92.118.64:10010] artid[146472]
==================
==================
artid[146472] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:52] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146456], title[淘宝也来了]
[[1;32mSUCC    [0m 04-05 12:11:52] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146456], title[淘宝也来了], table[article]
[[1;32mSUCC    [0m 04-05 12:11:52] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146456], title[淘宝也来了]
[[1;36mINFO    [0m 04-05 12:11:53] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146473]
==================
set proxy[https://120.92.118.64:10010] artid[146473]
==================
==================
artid[146473] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:53] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146457], title[]
[[1;32mSUCC    [0m 04-05 12:11:53] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146457], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:11:53] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146457], title[]
[[1;36mINFO    [0m 04-05 12:11:54] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146474]
==================
set proxy[https://120.92.118.64:10010] artid[146474]
==================
==================
artid[146474] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:55] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146458], title[]
[[1;32mSUCC    [0m 04-05 12:11:55] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146458], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:11:55] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146458], title[]
[[1;36mINFO    [0m 04-05 12:11:56] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146475]
==================
set proxy[https://120.92.118.64:10010] artid[146475]
==================
==================
artid[146475] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:56] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146459], title[EOS众筹地址转出60万个ETH意欲套现，众多大佬热议持仓选择]
[[1;32mSUCC    [0m 04-05 12:11:56] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146459], title[EOS众筹地址转出60万个ETH意欲套现，众多大佬热议持仓选择], table[article]
[[1;32mSUCC    [0m 04-05 12:11:56] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146459], title[EOS众筹地址转出60万个ETH意欲套现，众多大佬热议持仓选择]
[[1;36mINFO    [0m 04-05 12:11:57] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146476]
==================
set proxy[https://120.92.118.64:10010] artid[146476]
==================
==================
artid[146476] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:57] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146460], title[学习在币乎上排版]
[[1;32mSUCC    [0m 04-05 12:11:57] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146460], title[学习在币乎上排版], table[article]
[[1;32mSUCC    [0m 04-05 12:11:57] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146460], title[学习在币乎上排版]
[[1;36mINFO    [0m 04-05 12:11:59] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146477]
==================
set proxy[https://120.92.118.64:10010] artid[146477]
==================
==================
artid[146477] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:11:59] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146461], title[]
[[1;32mSUCC    [0m 04-05 12:11:59] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146461], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:11:59] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146461], title[]
[[1;36mINFO    [0m 04-05 12:12:00] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146478]
==================
set proxy[https://120.92.118.64:10010] artid[146478]
==================
==================
artid[146478] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:00] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146462], title[怎么没有彩票币]
[[1;32mSUCC    [0m 04-05 12:12:00] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146462], title[怎么没有彩票币], table[article]
[[1;32mSUCC    [0m 04-05 12:12:00] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146462], title[怎么没有彩票币]
[[1;36mINFO    [0m 04-05 12:12:03] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146479]
==================
set proxy[https://120.92.118.64:10010] artid[146479]
==================
==================
artid[146479] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:03] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146463], title[什么时候是底？]
[[1;32mSUCC    [0m 04-05 12:12:03] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146463], title[什么时候是底？], table[article]
[[1;32mSUCC    [0m 04-05 12:12:03] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146463], title[什么时候是底？]
[[1;36mINFO    [0m 04-05 12:12:03] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146480]
==================
set proxy[https://120.92.118.64:10010] artid[146480]
==================
==================
artid[146480] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:03] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146464], title[3月20日就提醒的重要利空！！]
[[1;32mSUCC    [0m 04-05 12:12:03] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146464], title[3月20日就提醒的重要利空！！], table[article]
[[1;32mSUCC    [0m 04-05 12:12:03] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146464], title[3月20日就提醒的重要利空！！]
[[1;36mINFO    [0m 04-05 12:12:04] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146481]
==================
set proxy[https://120.92.118.64:10010] artid[146481]
==================
==================
artid[146481] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:04] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146465], title[]
[[1;32mSUCC    [0m 04-05 12:12:04] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146465], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:12:04] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146465], title[]
[[1;36mINFO    [0m 04-05 12:12:06] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146482]
==================
set proxy[https://120.92.118.64:10010] artid[146482]
==================
==================
artid[146482] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:06] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146466], title[EOS超级节点之争，是“超级庄家” 间的一场 “名利双收” 的博弈！]
[[1;32mSUCC    [0m 04-05 12:12:06] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146466], title[EOS超级节点之争，是“超级庄家” 间的一场 “名利双收” 的博弈！], table[article]
[[1;32mSUCC    [0m 04-05 12:12:06] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146466], title[EOS超级节点之争，是“超级庄家” 间的一场 “名利双收” 的博弈！]
[[1;36mINFO    [0m 04-05 12:12:07] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146483]
==================
set proxy[https://120.92.118.64:10010] artid[146483]
==================
==================
artid[146483] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:07] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146467], title[]
[[1;32mSUCC    [0m 04-05 12:12:07] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146467], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:12:07] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146467], title[]
[[1;36mINFO    [0m 04-05 12:12:09] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146484]
==================
set proxy[https://120.92.118.64:10010] artid[146484]
==================
==================
artid[146484] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:09] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146468], title[马云爸爸的项目来了，今天内测]
[[1;32mSUCC    [0m 04-05 12:12:09] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146468], title[马云爸爸的项目来了，今天内测], table[article]
[[1;32mSUCC    [0m 04-05 12:12:09] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146468], title[马云爸爸的项目来了，今天内测]
[[1;36mINFO    [0m 04-05 12:12:10] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146485]
==================
set proxy[https://120.92.118.64:10010] artid[146485]
==================
==================
artid[146485] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:10] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146469], title[读书随处净土， 闭门即是深山]
[[1;32mSUCC    [0m 04-05 12:12:10] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146469], title[读书随处净土， 闭门即是深山], table[article]
[[1;32mSUCC    [0m 04-05 12:12:10] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146469], title[读书随处净土， 闭门即是深山]
[[1;36mINFO    [0m 04-05 12:12:11] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146486]
==================
set proxy[https://120.92.118.64:10010] artid[146486]
==================
==================
artid[146486] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:11] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146470], title[马爸爸的项目 分享]
[[1;32mSUCC    [0m 04-05 12:12:11] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146470], title[马爸爸的项目 分享], table[article]
[[1;32mSUCC    [0m 04-05 12:12:11] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146470], title[马爸爸的项目 分享]
[[1;36mINFO    [0m 04-05 12:12:12] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146487]
==================
set proxy[https://120.92.118.64:10010] artid[146487]
==================
==================
artid[146487] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:12] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146471], title[]
[[1;32mSUCC    [0m 04-05 12:12:12] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146471], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:12:12] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146471], title[]
[[1;36mINFO    [0m 04-05 12:12:13] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146488]
==================
set proxy[https://120.92.118.64:10010] artid[146488]
==================
==================
artid[146488] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:13] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146472], title[转折时刻已到]
[[1;32mSUCC    [0m 04-05 12:12:13] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146472], title[转折时刻已到], table[article]
[[1;32mSUCC    [0m 04-05 12:12:13] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146472], title[转折时刻已到]
[[1;36mINFO    [0m 04-05 12:12:15] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146489]
==================
set proxy[https://120.92.118.64:10010] artid[146489]
==================
==================
artid[146489] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:15] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146473], title[东京置业最小必要知识]
[[1;32mSUCC    [0m 04-05 12:12:15] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146473], title[东京置业最小必要知识], table[article]
[[1;32mSUCC    [0m 04-05 12:12:15] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146473], title[东京置业最小必要知识]
[[1;36mINFO    [0m 04-05 12:12:16] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146490]
==================
set proxy[https://120.92.118.64:10010] artid[146490]
==================
==================
artid[146490] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:16] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146474], title[比特币入门]
[[1;32mSUCC    [0m 04-05 12:12:16] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146474], title[比特币入门], table[article]
[[1;32mSUCC    [0m 04-05 12:12:16] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146474], title[比特币入门]
[[1;36mINFO    [0m 04-05 12:12:17] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146491]
==================
set proxy[https://120.92.118.64:10010] artid[146491]
==================
==================
artid[146491] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:17] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146475], title[不给活路，EOS团队再次提出68.5万个以太坊]
[[1;32mSUCC    [0m 04-05 12:12:17] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146475], title[不给活路，EOS团队再次提出68.5万个以太坊], table[article]
[[1;32mSUCC    [0m 04-05 12:12:17] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146475], title[不给活路，EOS团队再次提出68.5万个以太坊]
[[1;36mINFO    [0m 04-05 12:12:18] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146492]
==================
set proxy[https://120.92.118.64:10010] artid[146492]
==================
==================
artid[146492] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:18] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146476], title[]
[[1;32mSUCC    [0m 04-05 12:12:18] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146476], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:12:18] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146476], title[]
[[1;36mINFO    [0m 04-05 12:12:19] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146493]
==================
set proxy[https://120.92.118.64:10010] artid[146493]
==================
==================
artid[146493] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:19] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146477], title[继小米，百度，阿里巴巴也出区块链玩法了！]
[[1;32mSUCC    [0m 04-05 12:12:19] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146477], title[继小米，百度，阿里巴巴也出区块链玩法了！], table[article]
[[1;32mSUCC    [0m 04-05 12:12:19] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146477], title[继小米，百度，阿里巴巴也出区块链玩法了！]
[[1;36mINFO    [0m 04-05 12:12:21] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146494]
==================
set proxy[https://120.92.118.64:10010] artid[146494]
==================
==================
artid[146494] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:21] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146478], title[认知决定了每个人对区块链的态度]
[[1;32mSUCC    [0m 04-05 12:12:21] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146478], title[认知决定了每个人对区块链的态度], table[article]
[[1;32mSUCC    [0m 04-05 12:12:21] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146478], title[认知决定了每个人对区块链的态度]
[[1;36mINFO    [0m 04-05 12:12:22] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146495]
==================
set proxy[https://120.92.118.64:10010] artid[146495]
==================
==================
artid[146495] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:22] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146479], title[谁还记得我第一篇文章？btm]
[[1;32mSUCC    [0m 04-05 12:12:22] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146479], title[谁还记得我第一篇文章？btm], table[article]
[[1;32mSUCC    [0m 04-05 12:12:22] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146479], title[谁还记得我第一篇文章？btm]
[[1;36mINFO    [0m 04-05 12:12:23] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146496]
==================
set proxy[https://120.92.118.64:10010] artid[146496]
==================
==================
artid[146496] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:23] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146480], title[淘宝的新项目]
[[1;32mSUCC    [0m 04-05 12:12:23] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146480], title[淘宝的新项目], table[article]
[[1;32mSUCC    [0m 04-05 12:12:23] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146480], title[淘宝的新项目]
[[1;36mINFO    [0m 04-05 12:12:24] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146497]
==================
set proxy[https://120.92.118.64:10010] artid[146497]
==================
==================
artid[146497] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:24] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146481], title[【征文大赛】币圈人应该有的样子]
[[1;32mSUCC    [0m 04-05 12:12:24] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146481], title[【征文大赛】币圈人应该有的样子], table[article]
[[1;32mSUCC    [0m 04-05 12:12:24] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146481], title[【征文大赛】币圈人应该有的样子]
[[1;36mINFO    [0m 04-05 12:12:26] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146498]
==================
set proxy[https://120.92.118.64:10010] artid[146498]
==================
==================
artid[146498] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:26] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146482], title[我国年内将出台系列政策“组合拳” 推动区块链等热点产品及服务创新研发]
[[1;32mSUCC    [0m 04-05 12:12:26] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146482], title[我国年内将出台系列政策“组合拳” 推动区块链等热点产品及服务创新研发], table[article]
[[1;32mSUCC    [0m 04-05 12:12:26] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146482], title[我国年内将出台系列政策“组合拳” 推动区块链等热点产品及服务创新研发]
[[1;36mINFO    [0m 04-05 12:12:26] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146499]
==================
set proxy[https://120.92.118.64:10010] artid[146499]
==================
==================
artid[146499] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:26] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146483], title[q]
[[1;32mSUCC    [0m 04-05 12:12:26] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146483], title[q], table[article]
[[1;32mSUCC    [0m 04-05 12:12:27] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146483], title[q]
[[1;36mINFO    [0m 04-05 12:12:28] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146500]
==================
set proxy[https://120.92.118.64:10010] artid[146500]
==================
==================
artid[146500] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:28] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146484], title[大在]
[[1;32mSUCC    [0m 04-05 12:12:28] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146484], title[大在], table[article]
[[1;32mSUCC    [0m 04-05 12:12:28] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146484], title[大在]
[[1;36mINFO    [0m 04-05 12:12:29] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146501]
==================
set proxy[https://120.92.118.64:10010] artid[146501]
==================
==================
artid[146501] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:29] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146485], title[【午间币新闻30分】台湾印度出手数字货币等]
[[1;32mSUCC    [0m 04-05 12:12:29] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146485], title[【午间币新闻30分】台湾印度出手数字货币等], table[article]
[[1;32mSUCC    [0m 04-05 12:12:29] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146485], title[【午间币新闻30分】台湾印度出手数字货币等]
[[1;36mINFO    [0m 04-05 12:12:31] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146502]
==================
set proxy[https://120.92.118.64:10010] artid[146502]
==================
==================
artid[146502] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:31] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146486], title[区域链应用要落地]
[[1;32mSUCC    [0m 04-05 12:12:31] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146486], title[区域链应用要落地], table[article]
[[1;32mSUCC    [0m 04-05 12:12:31] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146486], title[区域链应用要落地]
[[1;36mINFO    [0m 04-05 12:12:31] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146503]
==================
set proxy[https://120.92.118.64:10010] artid[146503]
==================
==================
artid[146503] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:32] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146487], title[【原创:牛市在哪里】]
[[1;32mSUCC    [0m 04-05 12:12:32] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146487], title[【原创:牛市在哪里】], table[article]
[[1;32mSUCC    [0m 04-05 12:12:32] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146487], title[【原创:牛市在哪里】]
[[1;36mINFO    [0m 04-05 12:12:33] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146504]
==================
set proxy[https://120.92.118.64:10010] artid[146504]
==================
==================
artid[146504] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:33] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146488], title[知识忘了吗？]
[[1;32mSUCC    [0m 04-05 12:12:33] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146488], title[知识忘了吗？], table[article]
[[1;32mSUCC    [0m 04-05 12:12:33] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146488], title[知识忘了吗？]
[[1;36mINFO    [0m 04-05 12:12:34] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146505]
==================
set proxy[https://120.92.118.64:10010] artid[146505]
==================
==================
artid[146505] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:34] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146489], title[]
[[1;32mSUCC    [0m 04-05 12:12:34] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146489], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:12:34] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146489], title[]
[[1;36mINFO    [0m 04-05 12:12:35] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146506]
==================
set proxy[https://120.92.118.64:10010] artid[146506]
==================
==================
artid[146506] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:35] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146490], title[“特定虚拟币”,token,通证.]
[[1;32mSUCC    [0m 04-05 12:12:35] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146490], title[“特定虚拟币”,token,通证.], table[article]
[[1;32mSUCC    [0m 04-05 12:12:35] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146490], title[“特定虚拟币”,token,通证.]
[[1;36mINFO    [0m 04-05 12:12:36] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146507]
==================
set proxy[https://120.92.118.64:10010] artid[146507]
==================
==================
artid[146507] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:36] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146491], title[95后总裁挖出十亿以太坊 他承受着这个年纪不该有的才华……]
[[1;32mSUCC    [0m 04-05 12:12:36] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146491], title[95后总裁挖出十亿以太坊 他承受着这个年纪不该有的才华……], table[article]
[[1;32mSUCC    [0m 04-05 12:12:36] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146491], title[95后总裁挖出十亿以太坊 他承受着这个年纪不该有的才华……]
[[1;36mINFO    [0m 04-05 12:12:38] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146508]
==================
set proxy[https://120.92.118.64:10010] artid[146508]
==================
==================
artid[146508] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:38] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146492], title[key在octbtc上有卖的？]
[[1;32mSUCC    [0m 04-05 12:12:38] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146492], title[key在octbtc上有卖的？], table[article]
[[1;32mSUCC    [0m 04-05 12:12:38] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146492], title[key在octbtc上有卖的？]
[[1;36mINFO    [0m 04-05 12:12:39] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146509]
==================
set proxy[https://120.92.118.64:10010] artid[146509]
==================
==================
artid[146509] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:39] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146493], title[区块链创业日记-10（GDPR对于区块链的机会）]
[[1;32mSUCC    [0m 04-05 12:12:39] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146493], title[区块链创业日记-10（GDPR对于区块链的机会）], table[article]
[[1;32mSUCC    [0m 04-05 12:12:39] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146493], title[区块链创业日记-10（GDPR对于区块链的机会）]
[[1;36mINFO    [0m 04-05 12:12:41] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146510]
==================
set proxy[https://120.92.118.64:10010] artid[146510]
==================
==================
artid[146510] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:41] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146494], title[【原创：熊市何时休】]
[[1;32mSUCC    [0m 04-05 12:12:41] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146494], title[【原创：熊市何时休】], table[article]
[[1;32mSUCC    [0m 04-05 12:12:41] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146494], title[【原创：熊市何时休】]
[[1;36mINFO    [0m 04-05 12:12:42] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146511]
==================
set proxy[https://120.92.118.64:10010] artid[146511]
==================
==================
artid[146511] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:42] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146495], title[【通证经济】通证解救了程序员]
[[1;32mSUCC    [0m 04-05 12:12:42] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146495], title[【通证经济】通证解救了程序员], table[article]
[[1;32mSUCC    [0m 04-05 12:12:42] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146495], title[【通证经济】通证解救了程序员]
[[1;36mINFO    [0m 04-05 12:12:43] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146512]
==================
set proxy[https://120.92.118.64:10010] artid[146512]
==================
==================
artid[146512] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:43] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146496], title[《区块链之新》第一集：冒险从它开始]
[[1;32mSUCC    [0m 04-05 12:12:43] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146496], title[《区块链之新》第一集：冒险从它开始], table[article]
[[1;32mSUCC    [0m 04-05 12:12:43] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146496], title[《区块链之新》第一集：冒险从它开始]
[[1;36mINFO    [0m 04-05 12:12:44] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146513]
==================
set proxy[https://120.92.118.64:10010] artid[146513]
==================
==================
artid[146513] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:44] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146497], title[内心与行动差距的思考]
[[1;32mSUCC    [0m 04-05 12:12:44] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146497], title[内心与行动差距的思考], table[article]
[[1;32mSUCC    [0m 04-05 12:12:44] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146497], title[内心与行动差距的思考]
[[1;36mINFO    [0m 04-05 12:12:45] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146514]
==================
set proxy[https://120.92.118.64:10010] artid[146514]
==================
==================
artid[146514] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:45] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146498], title[]
[[1;32mSUCC    [0m 04-05 12:12:45] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146498], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:12:45] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146498], title[]
[[1;36mINFO    [0m 04-05 12:12:47] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146515]
==================
set proxy[https://120.92.118.64:10010] artid[146515]
==================
==================
artid[146515] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:47] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146499], title[ddddd3]
[[1;32mSUCC    [0m 04-05 12:12:47] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146499], title[ddddd3], table[article]
[[1;32mSUCC    [0m 04-05 12:12:47] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146499], title[ddddd3]
[[1;36mINFO    [0m 04-05 12:12:48] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146516]
==================
set proxy[https://120.92.118.64:10010] artid[146516]
==================
==================
artid[146516] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:48] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146500], title[阿里巴巴正式进军区块链！！！第一手注册链接！]
[[1;32mSUCC    [0m 04-05 12:12:48] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146500], title[阿里巴巴正式进军区块链！！！第一手注册链接！], table[article]
[[1;32mSUCC    [0m 04-05 12:12:48] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146500], title[阿里巴巴正式进军区块链！！！第一手注册链接！]
[[1;36mINFO    [0m 04-05 12:12:49] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146517]
==================
set proxy[https://120.92.118.64:10010] artid[146517]
==================
==================
artid[146517] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:49] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146501], title[淘宝弄的区块链，目前还是创世居民，速度围观]
[[1;32mSUCC    [0m 04-05 12:12:49] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146501], title[淘宝弄的区块链，目前还是创世居民，速度围观], table[article]
[[1;32mSUCC    [0m 04-05 12:12:49] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146501], title[淘宝弄的区块链，目前还是创世居民，速度围观]
[[1;36mINFO    [0m 04-05 12:12:50] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146518]
==================
set proxy[https://120.92.118.64:10010] artid[146518]
==================
==================
artid[146518] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:50] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146502], title[比特币的未来是未来]
[[1;32mSUCC    [0m 04-05 12:12:50] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146502], title[比特币的未来是未来], table[article]
[[1;32mSUCC    [0m 04-05 12:12:51] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146502], title[比特币的未来是未来]
[[1;36mINFO    [0m 04-05 12:12:51] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146519]
==================
set proxy[https://120.92.118.64:10010] artid[146519]
==================
==================
artid[146519] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:51] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146503], title[]
[[1;32mSUCC    [0m 04-05 12:12:51] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146503], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:12:51] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146503], title[]
[[1;36mINFO    [0m 04-05 12:12:53] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146520]
==================
set proxy[https://120.92.118.64:10010] artid[146520]
==================
==================
artid[146520] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:53] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146504], title[区块链PM成长记~4]
[[1;32mSUCC    [0m 04-05 12:12:53] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146504], title[区块链PM成长记~4], table[article]
[[1;32mSUCC    [0m 04-05 12:12:53] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146504], title[区块链PM成长记~4]
[[1;36mINFO    [0m 04-05 12:12:54] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146521]
==================
set proxy[https://120.92.118.64:10010] artid[146521]
==================
==================
artid[146521] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:54] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146505], title[]
[[1;32mSUCC    [0m 04-05 12:12:54] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146505], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:12:54] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146505], title[]
[[1;36mINFO    [0m 04-05 12:12:55] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146522]
==================
set proxy[https://120.92.118.64:10010] artid[146522]
==================
==================
artid[146522] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:55] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146506], title[]
[[1;32mSUCC    [0m 04-05 12:12:55] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146506], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:12:55] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146506], title[]
[[1;36mINFO    [0m 04-05 12:12:57] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146523]
==================
set proxy[https://120.92.118.64:10010] artid[146523]
==================
==================
artid[146523] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:57] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146507], title[来浅谈一下IPFS和Filecoin]
[[1;32mSUCC    [0m 04-05 12:12:57] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146507], title[来浅谈一下IPFS和Filecoin], table[article]
[[1;32mSUCC    [0m 04-05 12:12:57] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146507], title[来浅谈一下IPFS和Filecoin]
[[1;36mINFO    [0m 04-05 12:12:58] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146524]
==================
set proxy[https://120.92.118.64:10010] artid[146524]
==================
==================
artid[146524] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:58] [XZLog] [article_week_loop.py:149:parse_item] download article info: resMsg[], artid[146508], title[]
[[1;32mSUCC    [0m 04-05 12:12:58] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146508], title[], table[article]
[[1;32mSUCC    [0m 04-05 12:12:58] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146508], title[]
[[1;36mINFO    [0m 04-05 12:12:59] [XZLog] [article_week_loop.py:70:start_requests] start to download article, artid[146525]
==================
set proxy[https://120.92.118.64:10010] artid[146525]
==================
==================
artid[146525] proxy_index[3]
==================
[[1;32mSUCC    [0m 04-05 12:12:59] [XZLog] [article_week_loop.py:127:parse_item] download article info: resMsg[success], artid[146509], title[淘宝也挖矿！]
[[1;32mSUCC    [0m 04-05 12:12:59] [XZLog] [pipelines.py:67:process_item] Insert/update article to DB success, artid[146509], title[淘宝也挖矿！], table[article]
[[1;32mSUCC    [0m 04-05 12:12:59] [XZLog] [pipelines.py:89:process_item] Insert article to es success, artid[146509], title[淘宝也挖矿！]
